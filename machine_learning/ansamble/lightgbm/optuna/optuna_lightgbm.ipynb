{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9347363a-4559-4660-87d5-6a6beb07353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: inf:   0%|          | 0/7 [14:48:44<?, ?it/s]\n",
      "num_leaves, val_score: 0.602459:  35%|###5      | 7/20 [13:48:33<25:38:44, 7101.90s/it]\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [13:06:33<?, ?it/s]\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [11:56:55<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    symbol                 Name                  Sector\n",
      "0      MMM           3M Company             Industrials\n",
      "1      AOS      A.O. Smith Corp             Industrials\n",
      "2      ABT  Abbott Laboratories             Health Care\n",
      "3     ABBV          AbbVie Inc.             Health Care\n",
      "4     ABMD              Abiomed             Health Care\n",
      "..     ...                  ...                     ...\n",
      "500    YUM      Yum! Brands Inc  Consumer Discretionary\n",
      "501   ZBRA   Zebra Technologies  Information Technology\n",
      "502    ZBH        Zimmer Biomet             Health Care\n",
      "503   ZION        Zions Bancorp              Financials\n",
      "504    ZTS               Zoetis             Health Care\n",
      "\n",
      "[505 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-06-29 11:57:55,635]\u001b[0m A new study created in memory with name: no-name-5c361509-fa3e-4355-bd91-1b8705a5f87c\u001b[0m\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.357379\n",
      "[400]\tvalid_0's rmse: 0.353001\n",
      "[600]\tvalid_0's rmse: 0.349459\n",
      "[800]\tvalid_0's rmse: 0.346406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_fraction, val_score: 0.343767:   0%|          | 0/7 [00:20<?, ?it/s]\u001b[A\n",
      "feature_fraction, val_score: 0.343767:  14%|#4        | 1/7 [00:20<02:05, 20.89s/it]\u001b[A\u001b[32m[I 2021-06-29 11:58:16,700]\u001b[0m Trial 0 finished with value: 0.3437665680366974 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.3437665680366974.\u001b[0m\n",
      "\n",
      "feature_fraction, val_score: 0.343767:  14%|#4        | 1/7 [00:20<02:05, 20.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.343767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.343767\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.358449\n",
      "[400]\tvalid_0's rmse: 0.354459\n",
      "[600]\tvalid_0's rmse: 0.351412\n",
      "[800]\tvalid_0's rmse: 0.348822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_fraction, val_score: 0.343767:  14%|#4        | 1/7 [00:33<02:05, 20.89s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.343767:  29%|##8       | 2/7 [00:33<01:20, 16.09s/it]\u001b[A\u001b[32m[I 2021-06-29 11:58:29,484]\u001b[0m Trial 1 finished with value: 0.34652102548235547 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.3437665680366974.\u001b[0m\n",
      "\n",
      "feature_fraction, val_score: 0.343767:  29%|##8       | 2/7 [00:33<01:20, 16.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.346521\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.346521\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007404 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.357197\n",
      "[400]\tvalid_0's rmse: 0.35251\n",
      "[600]\tvalid_0's rmse: 0.34897\n",
      "[800]\tvalid_0's rmse: 0.34595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_fraction, val_score: 0.343315:  29%|##8       | 2/7 [00:55<01:20, 16.09s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.343315:  43%|####2     | 3/7 [00:55<01:15, 18.89s/it]\u001b[A\u001b[32m[I 2021-06-29 11:58:51,649]\u001b[0m Trial 2 finished with value: 0.3433154198501603 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.3433154198501603.\u001b[0m\n",
      "\n",
      "feature_fraction, val_score: 0.343315:  43%|####2     | 3/7 [00:55<01:15, 18.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.343315\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.343315\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.35736\n",
      "[400]\tvalid_0's rmse: 0.352899\n",
      "[600]\tvalid_0's rmse: 0.349272\n",
      "[800]\tvalid_0's rmse: 0.346076\n",
      "[1000]\tvalid_0's rmse: 0.343443\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.343443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_fraction, val_score: 0.343315:  43%|####2     | 3/7 [01:13<01:15, 18.89s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.343315:  57%|#####7    | 4/7 [01:13<00:55, 18.43s/it]\u001b[A\u001b[32m[I 2021-06-29 11:59:09,375]\u001b[0m Trial 3 finished with value: 0.3434427005871746 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.3433154198501603.\u001b[0m\n",
      "\n",
      "feature_fraction, val_score: 0.343315:  57%|#####7    | 4/7 [01:13<00:55, 18.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.35701\n",
      "[400]\tvalid_0's rmse: 0.352297\n",
      "[600]\tvalid_0's rmse: 0.348533\n",
      "[800]\tvalid_0's rmse: 0.345584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_fraction, val_score: 0.342843:  57%|#####7    | 4/7 [01:28<00:55, 18.43s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.342843:  71%|#######1  | 5/7 [01:28<00:34, 17.27s/it]\u001b[A\u001b[32m[I 2021-06-29 11:59:24,597]\u001b[0m Trial 4 finished with value: 0.34284260917961235 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 0.34284260917961235.\u001b[0m\n",
      "\n",
      "feature_fraction, val_score: 0.342843:  71%|#######1  | 5/7 [01:28<00:34, 17.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.342843\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.342843\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.357904\n",
      "[400]\tvalid_0's rmse: 0.353755\n",
      "[600]\tvalid_0's rmse: 0.350457\n",
      "[800]\tvalid_0's rmse: 0.347607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_fraction, val_score: 0.342843:  71%|#######1  | 5/7 [01:49<00:34, 17.27s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.342843:  86%|########5 | 6/7 [01:49<00:18, 18.44s/it]\u001b[A\u001b[32m[I 2021-06-29 11:59:45,313]\u001b[0m Trial 5 finished with value: 0.3452060910552961 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 0.34284260917961235.\u001b[0m\n",
      "\n",
      "feature_fraction, val_score: 0.342843:  86%|########5 | 6/7 [01:49<00:18, 18.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.345206\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.345206\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.357465\n",
      "[400]\tvalid_0's rmse: 0.35298\n",
      "[600]\tvalid_0's rmse: 0.349671\n",
      "[800]\tvalid_0's rmse: 0.346905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_fraction, val_score: 0.342843:  86%|########5 | 6/7 [02:04<00:18, 18.44s/it]\u001b[A\n",
      "feature_fraction, val_score: 0.342843: 100%|##########| 7/7 [02:04<00:00, 17.38s/it]\u001b[A\u001b[32m[I 2021-06-29 12:00:00,498]\u001b[0m Trial 6 finished with value: 0.344170413105249 and parameters: {'feature_fraction': 0.6}. Best is trial 4 with value: 0.34284260917961235.\u001b[0m\n",
      "feature_fraction, val_score: 0.342843: 100%|##########| 7/7 [02:04<00:00, 17.81s/it]\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.342843:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.34417\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.34417\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.362705\n",
      "[400]\tvalid_0's rmse: 0.360733\n",
      "[600]\tvalid_0's rmse: 0.359193\n",
      "[800]\tvalid_0's rmse: 0.357891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.342843:   0%|          | 0/20 [00:13<?, ?it/s]\u001b[A\n",
      "num_leaves, val_score: 0.342843:   5%|5         | 1/20 [00:13<04:22, 13.80s/it]\u001b[A\u001b[32m[I 2021-06-29 12:00:14,349]\u001b[0m Trial 7 finished with value: 0.35661082310570247 and parameters: {'num_leaves': 9}. Best is trial 7 with value: 0.35661082310570247.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.342843:   5%|5         | 1/20 [00:13<04:22, 13.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.356611\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.356611\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008954 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.35012\n",
      "[400]\tvalid_0's rmse: 0.342402\n",
      "[600]\tvalid_0's rmse: 0.336486\n",
      "[800]\tvalid_0's rmse: 0.331658\n",
      "[1000]\tvalid_0's rmse: 0.32759\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.32759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.327590:   5%|5         | 1/20 [00:41<04:22, 13.80s/it]\u001b[A\n",
      "num_leaves, val_score: 0.327590:  10%|#         | 2/20 [00:41<06:40, 22.26s/it]\u001b[A\u001b[32m[I 2021-06-29 12:00:42,521]\u001b[0m Trial 8 finished with value: 0.32758988812620093 and parameters: {'num_leaves': 78}. Best is trial 8 with value: 0.32758988812620093.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.327590:  10%|#         | 2/20 [00:41<06:40, 22.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.344036\n",
      "[400]\tvalid_0's rmse: 0.334296\n",
      "[600]\tvalid_0's rmse: 0.326886\n",
      "[800]\tvalid_0's rmse: 0.320953\n",
      "[1000]\tvalid_0's rmse: 0.315986\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.315986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.315986:  10%|#         | 2/20 [01:15<06:40, 22.26s/it]\u001b[A\n",
      "num_leaves, val_score: 0.315986:  15%|#5        | 3/20 [01:15<07:45, 27.37s/it]\u001b[A\u001b[32m[I 2021-06-29 12:01:15,972]\u001b[0m Trial 9 finished with value: 0.31598566156885866 and parameters: {'num_leaves': 138}. Best is trial 9 with value: 0.31598566156885866.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.315986:  15%|#5        | 3/20 [01:15<07:45, 27.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.337776\n",
      "[400]\tvalid_0's rmse: 0.325564\n",
      "[600]\tvalid_0's rmse: 0.317128\n",
      "[800]\tvalid_0's rmse: 0.310647\n",
      "[1000]\tvalid_0's rmse: 0.305188\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.305188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.305188:  15%|#5        | 3/20 [02:04<07:45, 27.37s/it]\u001b[A\n",
      "num_leaves, val_score: 0.305188:  20%|##        | 4/20 [02:04<09:34, 35.88s/it]\u001b[A\u001b[32m[I 2021-06-29 12:02:04,893]\u001b[0m Trial 10 finished with value: 0.30518831824207737 and parameters: {'num_leaves': 218}. Best is trial 10 with value: 0.30518831824207737.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.305188:  20%|##        | 4/20 [02:04<09:34, 35.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.347694\n",
      "[400]\tvalid_0's rmse: 0.33918\n",
      "[600]\tvalid_0's rmse: 0.332633\n",
      "[800]\tvalid_0's rmse: 0.327738\n",
      "[1000]\tvalid_0's rmse: 0.323308\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.323308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.305188:  20%|##        | 4/20 [02:29<09:34, 35.88s/it]\u001b[A\n",
      "num_leaves, val_score: 0.305188:  25%|##5       | 5/20 [02:29<08:00, 32.06s/it]\u001b[A\u001b[32m[I 2021-06-29 12:02:30,182]\u001b[0m Trial 11 finished with value: 0.32330754671329426 and parameters: {'num_leaves': 98}. Best is trial 10 with value: 0.30518831824207737.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.305188:  25%|##5       | 5/20 [02:29<08:00, 32.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.348278\n",
      "[400]\tvalid_0's rmse: 0.33981\n",
      "[600]\tvalid_0's rmse: 0.333457\n",
      "[800]\tvalid_0's rmse: 0.328279\n",
      "[1000]\tvalid_0's rmse: 0.324295\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.324295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.305188:  25%|##5       | 5/20 [02:58<08:00, 32.06s/it]\u001b[A\n",
      "num_leaves, val_score: 0.305188:  30%|###       | 6/20 [02:58<07:15, 31.13s/it]\u001b[A\u001b[32m[I 2021-06-29 12:02:59,507]\u001b[0m Trial 12 finished with value: 0.32429521649013854 and parameters: {'num_leaves': 94}. Best is trial 10 with value: 0.30518831824207737.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.305188:  30%|###       | 6/20 [02:58<07:15, 31.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.336187\n",
      "[400]\tvalid_0's rmse: 0.324136\n",
      "[600]\tvalid_0's rmse: 0.315356\n",
      "[800]\tvalid_0's rmse: 0.30859\n",
      "[1000]\tvalid_0's rmse: 0.303187\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.303187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.303187:  30%|###       | 6/20 [03:47<07:15, 31.13s/it]\u001b[A\n",
      "num_leaves, val_score: 0.303187:  35%|###5      | 7/20 [03:47<08:00, 36.94s/it]\u001b[A\u001b[32m[I 2021-06-29 12:03:48,415]\u001b[0m Trial 13 finished with value: 0.30318673896392423 and parameters: {'num_leaves': 238}. Best is trial 13 with value: 0.30318673896392423.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.303187:  35%|###5      | 7/20 [03:47<08:00, 36.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.345045\n",
      "[400]\tvalid_0's rmse: 0.336045\n",
      "[600]\tvalid_0's rmse: 0.328722\n",
      "[800]\tvalid_0's rmse: 0.323194\n",
      "[1000]\tvalid_0's rmse: 0.318324\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.318324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.303187:  35%|###5      | 7/20 [04:23<08:00, 36.94s/it]\u001b[A\n",
      "num_leaves, val_score: 0.303187:  40%|####      | 8/20 [04:23<07:16, 36.39s/it]\u001b[A\u001b[32m[I 2021-06-29 12:04:23,636]\u001b[0m Trial 14 finished with value: 0.31832387129192957 and parameters: {'num_leaves': 125}. Best is trial 13 with value: 0.30318673896392423.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.303187:  40%|####      | 8/20 [04:23<07:16, 36.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.338353\n",
      "[400]\tvalid_0's rmse: 0.326624\n",
      "[600]\tvalid_0's rmse: 0.318066\n",
      "[800]\tvalid_0's rmse: 0.311283\n",
      "[1000]\tvalid_0's rmse: 0.305917\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.305917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.303187:  40%|####      | 8/20 [05:10<07:16, 36.39s/it]\u001b[A\n",
      "num_leaves, val_score: 0.303187:  45%|####5     | 9/20 [05:10<07:16, 39.72s/it]\u001b[A\u001b[32m[I 2021-06-29 12:05:10,665]\u001b[0m Trial 15 finished with value: 0.3059173822563493 and parameters: {'num_leaves': 210}. Best is trial 13 with value: 0.30318673896392423.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.303187:  45%|####5     | 9/20 [05:10<07:16, 39.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.361054\n",
      "[400]\tvalid_0's rmse: 0.358251\n",
      "[600]\tvalid_0's rmse: 0.356126\n",
      "[800]\tvalid_0's rmse: 0.35431\n",
      "[1000]\tvalid_0's rmse: 0.352624\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.352624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.303187:  45%|####5     | 9/20 [05:23<07:16, 39.72s/it]\u001b[A\n",
      "num_leaves, val_score: 0.303187:  50%|#####     | 10/20 [05:24<05:17, 31.74s/it]\u001b[A\u001b[32m[I 2021-06-29 12:05:24,552]\u001b[0m Trial 16 finished with value: 0.3526239310255164 and parameters: {'num_leaves': 14}. Best is trial 13 with value: 0.30318673896392423.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.303187:  50%|#####     | 10/20 [05:24<05:17, 31.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335366\n",
      "[400]\tvalid_0's rmse: 0.322741\n",
      "[600]\tvalid_0's rmse: 0.313591\n",
      "[800]\tvalid_0's rmse: 0.307012\n",
      "[1000]\tvalid_0's rmse: 0.30158\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.30158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.301580:  50%|#####     | 10/20 [06:22<05:17, 31.74s/it]\u001b[A\n",
      "num_leaves, val_score: 0.301580:  55%|#####5    | 11/20 [06:22<06:00, 40.06s/it]\u001b[A\u001b[32m[I 2021-06-29 12:06:23,447]\u001b[0m Trial 17 finished with value: 0.30157977469360686 and parameters: {'num_leaves': 253}. Best is trial 17 with value: 0.30157977469360686.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.301580:  55%|#####5    | 11/20 [06:22<06:00, 40.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335793\n",
      "[400]\tvalid_0's rmse: 0.322922\n",
      "[600]\tvalid_0's rmse: 0.313778\n",
      "[800]\tvalid_0's rmse: 0.306668\n",
      "[1000]\tvalid_0's rmse: 0.300975\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.300975:  55%|#####5    | 11/20 [07:14<06:00, 40.06s/it]\u001b[A\n",
      "num_leaves, val_score: 0.300975:  60%|######    | 12/20 [07:14<05:47, 43.42s/it]\u001b[A\u001b[32m[I 2021-06-29 12:07:14,558]\u001b[0m Trial 18 finished with value: 0.3009745946203097 and parameters: {'num_leaves': 252}. Best is trial 18 with value: 0.3009745946203097.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.300975:  60%|######    | 12/20 [07:14<05:47, 43.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.339929\n",
      "[400]\tvalid_0's rmse: 0.32929\n",
      "[600]\tvalid_0's rmse: 0.321458\n",
      "[800]\tvalid_0's rmse: 0.314825\n",
      "[1000]\tvalid_0's rmse: 0.309825\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.309825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.300975:  60%|######    | 12/20 [07:55<05:47, 43.42s/it]\u001b[A\n",
      "num_leaves, val_score: 0.300975:  65%|######5   | 13/20 [07:56<05:00, 42.98s/it]\u001b[A\u001b[32m[I 2021-06-29 12:07:56,543]\u001b[0m Trial 19 finished with value: 0.30982519696549204 and parameters: {'num_leaves': 185}. Best is trial 18 with value: 0.3009745946203097.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.300975:  65%|######5   | 13/20 [07:56<05:00, 42.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335609\n",
      "[400]\tvalid_0's rmse: 0.322962\n",
      "[600]\tvalid_0's rmse: 0.313956\n",
      "[800]\tvalid_0's rmse: 0.307024\n",
      "[1000]\tvalid_0's rmse: 0.301426\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.301426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.300975:  65%|######5   | 13/20 [08:47<05:00, 42.98s/it]\u001b[A\n",
      "num_leaves, val_score: 0.300975:  70%|#######   | 14/20 [08:47<04:33, 45.65s/it]\u001b[A\u001b[32m[I 2021-06-29 12:08:48,370]\u001b[0m Trial 20 finished with value: 0.3014259014525753 and parameters: {'num_leaves': 251}. Best is trial 18 with value: 0.3009745946203097.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.300975:  70%|#######   | 14/20 [08:47<04:33, 45.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.341477\n",
      "[400]\tvalid_0's rmse: 0.330364\n",
      "[600]\tvalid_0's rmse: 0.322642\n",
      "[800]\tvalid_0's rmse: 0.31631\n",
      "[1000]\tvalid_0's rmse: 0.311281\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.311281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.300975:  70%|#######   | 14/20 [09:31<04:33, 45.65s/it]\u001b[A\n",
      "num_leaves, val_score: 0.300975:  75%|#######5  | 15/20 [09:31<03:45, 45.07s/it]\u001b[A\u001b[32m[I 2021-06-29 12:09:32,087]\u001b[0m Trial 21 finished with value: 0.3112806794448279 and parameters: {'num_leaves': 172}. Best is trial 18 with value: 0.3009745946203097.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.300975:  75%|#######5  | 15/20 [09:31<03:45, 45.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335366\n",
      "[400]\tvalid_0's rmse: 0.322741\n",
      "[600]\tvalid_0's rmse: 0.313591\n",
      "[800]\tvalid_0's rmse: 0.307012\n",
      "[1000]\tvalid_0's rmse: 0.30158\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.30158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.300975:  75%|#######5  | 15/20 [10:23<03:45, 45.07s/it]\u001b[A\n",
      "num_leaves, val_score: 0.300975:  80%|########  | 16/20 [10:23<03:08, 47.19s/it]\u001b[A\u001b[32m[I 2021-06-29 12:10:24,186]\u001b[0m Trial 22 finished with value: 0.30157977469360686 and parameters: {'num_leaves': 253}. Best is trial 18 with value: 0.3009745946203097.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.300975:  80%|########  | 16/20 [10:23<03:08, 47.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.339676\n",
      "[400]\tvalid_0's rmse: 0.328314\n",
      "[600]\tvalid_0's rmse: 0.320189\n",
      "[800]\tvalid_0's rmse: 0.313876\n",
      "[1000]\tvalid_0's rmse: 0.308907\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.308907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.300975:  80%|########  | 16/20 [11:08<03:08, 47.19s/it]\u001b[A\n",
      "num_leaves, val_score: 0.300975:  85%|########5 | 17/20 [11:08<02:19, 46.35s/it]\u001b[A\u001b[32m[I 2021-06-29 12:11:08,599]\u001b[0m Trial 23 finished with value: 0.3089074182963639 and parameters: {'num_leaves': 190}. Best is trial 18 with value: 0.3009745946203097.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.300975:  85%|########5 | 17/20 [11:08<02:19, 46.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.337102\n",
      "[400]\tvalid_0's rmse: 0.325062\n",
      "[600]\tvalid_0's rmse: 0.316328\n",
      "[800]\tvalid_0's rmse: 0.3095\n",
      "[1000]\tvalid_0's rmse: 0.304566\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.304566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.300975:  85%|########5 | 17/20 [11:52<02:19, 46.35s/it]\u001b[A\n",
      "num_leaves, val_score: 0.300975:  90%|######### | 18/20 [11:52<01:31, 45.84s/it]\u001b[A\u001b[32m[I 2021-06-29 12:11:53,255]\u001b[0m Trial 24 finished with value: 0.3045659482431162 and parameters: {'num_leaves': 230}. Best is trial 18 with value: 0.3009745946203097.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.300975:  90%|######### | 18/20 [11:52<01:31, 45.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.341545\n",
      "[400]\tvalid_0's rmse: 0.331056\n",
      "[600]\tvalid_0's rmse: 0.32382\n",
      "[800]\tvalid_0's rmse: 0.317647\n",
      "[1000]\tvalid_0's rmse: 0.312461\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.312461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.300975:  90%|######### | 18/20 [12:27<01:31, 45.84s/it]\u001b[A\n",
      "num_leaves, val_score: 0.300975:  95%|#########5| 19/20 [12:27<00:42, 42.66s/it]\u001b[A\u001b[32m[I 2021-06-29 12:12:28,485]\u001b[0m Trial 25 finished with value: 0.3124611713381421 and parameters: {'num_leaves': 162}. Best is trial 18 with value: 0.3009745946203097.\u001b[0m\n",
      "\n",
      "num_leaves, val_score: 0.300975:  95%|#########5| 19/20 [12:27<00:42, 42.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335317\n",
      "[400]\tvalid_0's rmse: 0.322337\n",
      "[600]\tvalid_0's rmse: 0.313526\n",
      "[800]\tvalid_0's rmse: 0.306777\n",
      "[1000]\tvalid_0's rmse: 0.301288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.301288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "num_leaves, val_score: 0.300975:  95%|#########5| 19/20 [13:24<00:42, 42.66s/it]\u001b[A\n",
      "num_leaves, val_score: 0.300975: 100%|##########| 20/20 [13:24<00:00, 46.88s/it]\u001b[A\u001b[32m[I 2021-06-29 12:13:25,199]\u001b[0m Trial 26 finished with value: 0.3012883139050949 and parameters: {'num_leaves': 255}. Best is trial 18 with value: 0.3009745946203097.\u001b[0m\n",
      "num_leaves, val_score: 0.300975: 100%|##########| 20/20 [13:24<00:00, 40.23s/it]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.300975:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.337138\n",
      "[400]\tvalid_0's rmse: 0.324802\n",
      "[600]\tvalid_0's rmse: 0.316312\n",
      "[800]\tvalid_0's rmse: 0.309864\n",
      "[1000]\tvalid_0's rmse: 0.304603\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.304603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "bagging, val_score: 0.300975:   0%|          | 0/10 [01:09<?, ?it/s]\u001b[A\n",
      "bagging, val_score: 0.300975:  10%|#         | 1/10 [01:09<10:26, 69.63s/it]\u001b[A\u001b[32m[I 2021-06-29 12:14:34,873]\u001b[0m Trial 27 finished with value: 0.3046027720832516 and parameters: {'bagging_fraction': 0.45552482409462597, 'bagging_freq': 5}. Best is trial 27 with value: 0.3046027720832516.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.300975:  10%|#         | 1/10 [01:09<10:26, 69.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.336072\n",
      "[400]\tvalid_0's rmse: 0.324152\n",
      "[600]\tvalid_0's rmse: 0.315592\n",
      "[800]\tvalid_0's rmse: 0.308811\n",
      "[1000]\tvalid_0's rmse: 0.303621\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.303621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "bagging, val_score: 0.300975:  10%|#         | 1/10 [02:20<10:26, 69.63s/it]\u001b[A\n",
      "bagging, val_score: 0.300975:  20%|##        | 2/10 [02:20<09:22, 70.29s/it]\u001b[A\u001b[32m[I 2021-06-29 12:15:45,633]\u001b[0m Trial 28 finished with value: 0.3036205864518517 and parameters: {'bagging_fraction': 0.519594019272455, 'bagging_freq': 3}. Best is trial 28 with value: 0.3036205864518517.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.300975:  20%|##        | 2/10 [02:20<09:22, 70.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335416\n",
      "[400]\tvalid_0's rmse: 0.322757\n",
      "[600]\tvalid_0's rmse: 0.314073\n",
      "[800]\tvalid_0's rmse: 0.306757\n",
      "[1000]\tvalid_0's rmse: 0.301141\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.301141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "bagging, val_score: 0.300975:  20%|##        | 2/10 [03:15<09:22, 70.29s/it]\u001b[A\n",
      "bagging, val_score: 0.300975:  30%|###       | 3/10 [03:15<07:23, 63.33s/it]\u001b[A\u001b[32m[I 2021-06-29 12:16:40,684]\u001b[0m Trial 29 finished with value: 0.30114114000995873 and parameters: {'bagging_fraction': 0.9875428590727894, 'bagging_freq': 1}. Best is trial 29 with value: 0.30114114000995873.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.300975:  30%|###       | 3/10 [03:15<07:23, 63.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335951\n",
      "[400]\tvalid_0's rmse: 0.323667\n",
      "[600]\tvalid_0's rmse: 0.314812\n",
      "[800]\tvalid_0's rmse: 0.30792\n",
      "[1000]\tvalid_0's rmse: 0.302719\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.302719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "bagging, val_score: 0.300975:  30%|###       | 3/10 [04:28<07:23, 63.33s/it]\u001b[A\n",
      "bagging, val_score: 0.300975:  40%|####      | 4/10 [04:28<06:43, 67.26s/it]\u001b[A\u001b[32m[I 2021-06-29 12:17:53,965]\u001b[0m Trial 30 finished with value: 0.3027194261821413 and parameters: {'bagging_fraction': 0.538205829115218, 'bagging_freq': 3}. Best is trial 29 with value: 0.30114114000995873.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.300975:  40%|####      | 4/10 [04:28<06:43, 67.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.33559\n",
      "[400]\tvalid_0's rmse: 0.322992\n",
      "[600]\tvalid_0's rmse: 0.313871\n",
      "[800]\tvalid_0's rmse: 0.307095\n",
      "[1000]\tvalid_0's rmse: 0.300982\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "bagging, val_score: 0.300975:  40%|####      | 4/10 [05:23<06:43, 67.26s/it]\u001b[A\n",
      "bagging, val_score: 0.300975:  50%|#####     | 5/10 [05:23<05:13, 62.70s/it]\u001b[A\u001b[32m[I 2021-06-29 12:18:48,591]\u001b[0m Trial 31 finished with value: 0.30098249897469315 and parameters: {'bagging_fraction': 0.9885196660984801, 'bagging_freq': 1}. Best is trial 31 with value: 0.30098249897469315.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.300975:  50%|#####     | 5/10 [05:23<05:13, 62.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.336695\n",
      "[400]\tvalid_0's rmse: 0.324872\n",
      "[600]\tvalid_0's rmse: 0.31601\n",
      "[800]\tvalid_0's rmse: 0.309687\n",
      "[1000]\tvalid_0's rmse: 0.304669\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.304669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "bagging, val_score: 0.300975:  50%|#####     | 5/10 [06:31<05:13, 62.70s/it]\u001b[A\n",
      "bagging, val_score: 0.300975:  60%|######    | 6/10 [06:31<04:18, 64.59s/it]\u001b[A\u001b[32m[I 2021-06-29 12:19:56,832]\u001b[0m Trial 32 finished with value: 0.3046687322878784 and parameters: {'bagging_fraction': 0.49305716838700725, 'bagging_freq': 6}. Best is trial 31 with value: 0.30098249897469315.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.300975:  60%|######    | 6/10 [06:31<04:18, 64.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008859 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335203\n",
      "[400]\tvalid_0's rmse: 0.322297\n",
      "[600]\tvalid_0's rmse: 0.313461\n",
      "[800]\tvalid_0's rmse: 0.306582\n",
      "[1000]\tvalid_0's rmse: 0.301203\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's rmse: 0.301199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "bagging, val_score: 0.300975:  60%|######    | 6/10 [07:32<04:18, 64.59s/it]\u001b[A\n",
      "bagging, val_score: 0.300975:  70%|#######   | 7/10 [07:32<03:10, 63.45s/it]\u001b[A\u001b[32m[I 2021-06-29 12:20:57,926]\u001b[0m Trial 33 finished with value: 0.30119919680977814 and parameters: {'bagging_fraction': 0.9345485242903906, 'bagging_freq': 7}. Best is trial 31 with value: 0.30098249897469315.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.300975:  70%|#######   | 7/10 [07:32<03:10, 63.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.337603\n",
      "[400]\tvalid_0's rmse: 0.325913\n",
      "[600]\tvalid_0's rmse: 0.317714\n",
      "[800]\tvalid_0's rmse: 0.311657\n",
      "[1000]\tvalid_0's rmse: 0.306487\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.306487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "bagging, val_score: 0.300975:  70%|#######   | 7/10 [08:47<03:10, 63.45s/it]\u001b[A\n",
      "bagging, val_score: 0.300975:  80%|########  | 8/10 [08:47<02:14, 67.09s/it]\u001b[A\u001b[32m[I 2021-06-29 12:22:12,832]\u001b[0m Trial 34 finished with value: 0.30648686263645875 and parameters: {'bagging_fraction': 0.425329037102692, 'bagging_freq': 7}. Best is trial 31 with value: 0.30098249897469315.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.300975:  80%|########  | 8/10 [08:47<02:14, 67.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.33775\n",
      "[400]\tvalid_0's rmse: 0.325735\n",
      "[600]\tvalid_0's rmse: 0.317482\n",
      "[800]\tvalid_0's rmse: 0.311376\n",
      "[1000]\tvalid_0's rmse: 0.306327\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.306327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "bagging, val_score: 0.300975:  80%|########  | 8/10 [09:54<02:14, 67.09s/it]\u001b[A\n",
      "bagging, val_score: 0.300975:  90%|######### | 9/10 [09:55<01:07, 67.19s/it]\u001b[A\u001b[32m[I 2021-06-29 12:23:20,247]\u001b[0m Trial 35 finished with value: 0.30632723026013403 and parameters: {'bagging_fraction': 0.4161447272365854, 'bagging_freq': 7}. Best is trial 31 with value: 0.30098249897469315.\u001b[0m\n",
      "\n",
      "bagging, val_score: 0.300975:  90%|######### | 9/10 [09:55<01:07, 67.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.334684\n",
      "[400]\tvalid_0's rmse: 0.321872\n",
      "[600]\tvalid_0's rmse: 0.313199\n",
      "[800]\tvalid_0's rmse: 0.306135\n",
      "[1000]\tvalid_0's rmse: 0.300244\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "bagging, val_score: 0.300244:  90%|######### | 9/10 [10:58<01:07, 67.19s/it]\u001b[A\n",
      "bagging, val_score: 0.300244: 100%|##########| 10/10 [10:58<00:00, 66.20s/it]\u001b[A\u001b[32m[I 2021-06-29 12:24:24,233]\u001b[0m Trial 36 finished with value: 0.3002435076710001 and parameters: {'bagging_fraction': 0.7850836052089633, 'bagging_freq': 3}. Best is trial 36 with value: 0.3002435076710001.\u001b[0m\n",
      "bagging, val_score: 0.300244: 100%|##########| 10/10 [10:59<00:00, 65.90s/it]\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.300244:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335266\n",
      "[400]\tvalid_0's rmse: 0.32288\n",
      "[600]\tvalid_0's rmse: 0.313492\n",
      "[800]\tvalid_0's rmse: 0.306575\n",
      "[1000]\tvalid_0's rmse: 0.301281\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.301281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_fraction_stage2, val_score: 0.300244:   0%|          | 0/3 [01:05<?, ?it/s]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.300244:  33%|###3      | 1/3 [01:05<02:11, 65.58s/it]\u001b[A\u001b[32m[I 2021-06-29 12:25:29,935]\u001b[0m Trial 37 finished with value: 0.3012813213049048 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 37 with value: 0.3012813213049048.\u001b[0m\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.300244:  33%|###3      | 1/3 [01:05<02:11, 65.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335266\n",
      "[400]\tvalid_0's rmse: 0.32288\n",
      "[600]\tvalid_0's rmse: 0.313492\n",
      "[800]\tvalid_0's rmse: 0.306575\n",
      "[1000]\tvalid_0's rmse: 0.301281\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.301281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_fraction_stage2, val_score: 0.300244:  33%|###3      | 1/3 [02:11<02:11, 65.58s/it]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.300244:  67%|######6   | 2/3 [02:11<01:05, 66.00s/it]\u001b[A\u001b[32m[I 2021-06-29 12:26:36,218]\u001b[0m Trial 38 finished with value: 0.3012813213049048 and parameters: {'feature_fraction': 0.92}. Best is trial 37 with value: 0.3012813213049048.\u001b[0m\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.300244:  67%|######6   | 2/3 [02:11<01:05, 66.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.334684\n",
      "[400]\tvalid_0's rmse: 0.321872\n",
      "[600]\tvalid_0's rmse: 0.313199\n",
      "[800]\tvalid_0's rmse: 0.306135\n",
      "[1000]\tvalid_0's rmse: 0.300244\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_fraction_stage2, val_score: 0.300244:  67%|######6   | 2/3 [03:16<01:05, 66.00s/it]\u001b[A\n",
      "feature_fraction_stage2, val_score: 0.300244: 100%|##########| 3/3 [03:16<00:00, 65.48s/it]\u001b[A\u001b[32m[I 2021-06-29 12:27:41,077]\u001b[0m Trial 39 finished with value: 0.3002435076710001 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 39 with value: 0.3002435076710001.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.300244: 100%|##########| 3/3 [03:16<00:00, 65.58s/it]\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.300244:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335219\n",
      "[400]\tvalid_0's rmse: 0.322249\n",
      "[600]\tvalid_0's rmse: 0.312935\n",
      "[800]\tvalid_0's rmse: 0.30586\n",
      "[1000]\tvalid_0's rmse: 0.300267\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.300244:   0%|          | 0/20 [01:08<?, ?it/s]\u001b[A\n",
      "regularization_factors, val_score: 0.300244:   5%|5         | 1/20 [01:08<21:38, 68.32s/it]\u001b[A\u001b[32m[I 2021-06-29 12:28:49,438]\u001b[0m Trial 40 finished with value: 0.3002665070964257 and parameters: {'lambda_l1': 0.0005789372116317734, 'lambda_l2': 0.0005231732470681798}. Best is trial 40 with value: 0.3002665070964257.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.300244:   5%|5         | 1/20 [01:08<21:38, 68.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.334964\n",
      "[400]\tvalid_0's rmse: 0.322027\n",
      "[600]\tvalid_0's rmse: 0.312747\n",
      "[800]\tvalid_0's rmse: 0.305285\n",
      "[1000]\tvalid_0's rmse: 0.299873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.299873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.299873:   5%|5         | 1/20 [02:17<21:38, 68.32s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.299873:  10%|#         | 2/20 [02:17<20:43, 69.09s/it]\u001b[A\u001b[32m[I 2021-06-29 12:29:59,063]\u001b[0m Trial 41 finished with value: 0.29987321787518195 and parameters: {'lambda_l1': 0.010561801699624031, 'lambda_l2': 0.11270384932406848}. Best is trial 41 with value: 0.29987321787518195.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.299873:  10%|#         | 2/20 [02:17<20:43, 69.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335302\n",
      "[400]\tvalid_0's rmse: 0.321834\n",
      "[600]\tvalid_0's rmse: 0.312753\n",
      "[800]\tvalid_0's rmse: 0.305568\n",
      "[1000]\tvalid_0's rmse: 0.300031\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.299873:  10%|#         | 2/20 [03:33<20:43, 69.09s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.299873:  15%|#5        | 3/20 [03:33<20:23, 71.95s/it]\u001b[A\u001b[32m[I 2021-06-29 12:31:14,429]\u001b[0m Trial 42 finished with value: 0.30003092823163846 and parameters: {'lambda_l1': 0.019827994117598988, 'lambda_l2': 0.000442226473085915}. Best is trial 41 with value: 0.29987321787518195.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.299873:  15%|#5        | 3/20 [03:33<20:23, 71.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335342\n",
      "[400]\tvalid_0's rmse: 0.322284\n",
      "[600]\tvalid_0's rmse: 0.313381\n",
      "[800]\tvalid_0's rmse: 0.306177\n",
      "[1000]\tvalid_0's rmse: 0.300665\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.299873:  15%|#5        | 3/20 [04:38<20:23, 71.95s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.299873:  20%|##        | 4/20 [04:38<18:27, 69.20s/it]\u001b[A\u001b[32m[I 2021-06-29 12:32:19,401]\u001b[0m Trial 43 finished with value: 0.3006654044780633 and parameters: {'lambda_l1': 0.0025093612395124445, 'lambda_l2': 1.239400215612854e-05}. Best is trial 41 with value: 0.29987321787518195.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.299873:  20%|##        | 4/20 [04:38<18:27, 69.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335142\n",
      "[400]\tvalid_0's rmse: 0.322201\n",
      "[600]\tvalid_0's rmse: 0.31302\n",
      "[800]\tvalid_0's rmse: 0.305814\n",
      "[1000]\tvalid_0's rmse: 0.300411\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.299873:  20%|##        | 4/20 [05:45<18:27, 69.20s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.299873:  25%|##5       | 5/20 [05:45<17:07, 68.48s/it]\u001b[A\u001b[32m[I 2021-06-29 12:33:26,603]\u001b[0m Trial 44 finished with value: 0.3004111843228489 and parameters: {'lambda_l1': 2.232432532442746e-06, 'lambda_l2': 8.872013437966743e-08}. Best is trial 41 with value: 0.29987321787518195.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.299873:  25%|##5       | 5/20 [05:45<17:07, 68.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335321\n",
      "[400]\tvalid_0's rmse: 0.322213\n",
      "[600]\tvalid_0's rmse: 0.312458\n",
      "[800]\tvalid_0's rmse: 0.305121\n",
      "[1000]\tvalid_0's rmse: 0.299769\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.299769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.299769:  25%|##5       | 5/20 [06:51<17:07, 68.48s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.299769:  30%|###       | 6/20 [06:51<15:46, 67.58s/it]\u001b[A\u001b[32m[I 2021-06-29 12:34:32,437]\u001b[0m Trial 45 finished with value: 0.29976875646604645 and parameters: {'lambda_l1': 0.07865249378704936, 'lambda_l2': 4.0967756013465313e-07}. Best is trial 45 with value: 0.29976875646604645.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.299769:  30%|###       | 6/20 [06:51<15:46, 67.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335111\n",
      "[400]\tvalid_0's rmse: 0.322228\n",
      "[600]\tvalid_0's rmse: 0.313056\n",
      "[800]\tvalid_0's rmse: 0.305823\n",
      "[1000]\tvalid_0's rmse: 0.300124\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.299769:  30%|###       | 6/20 [08:01<15:46, 67.58s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.299769:  35%|###5      | 7/20 [08:01<14:48, 68.31s/it]\u001b[A\u001b[32m[I 2021-06-29 12:35:42,269]\u001b[0m Trial 46 finished with value: 0.30012358706545106 and parameters: {'lambda_l1': 0.04054973018460472, 'lambda_l2': 0.20767465067091806}. Best is trial 45 with value: 0.29976875646604645.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.299769:  35%|###5      | 7/20 [08:01<14:48, 68.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.334648\n",
      "[400]\tvalid_0's rmse: 0.321688\n",
      "[600]\tvalid_0's rmse: 0.312845\n",
      "[800]\tvalid_0's rmse: 0.305761\n",
      "[1000]\tvalid_0's rmse: 0.300565\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.299769:  35%|###5      | 7/20 [09:06<14:48, 68.31s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.299769:  40%|####      | 8/20 [09:06<13:30, 67.52s/it]\u001b[A\u001b[32m[I 2021-06-29 12:36:48,079]\u001b[0m Trial 47 finished with value: 0.30056526316509097 and parameters: {'lambda_l1': 1.295807605514499e-08, 'lambda_l2': 1.5718669657339361e-06}. Best is trial 45 with value: 0.29976875646604645.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.299769:  40%|####      | 8/20 [09:06<13:30, 67.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.334615\n",
      "[400]\tvalid_0's rmse: 0.322131\n",
      "[600]\tvalid_0's rmse: 0.312818\n",
      "[800]\tvalid_0's rmse: 0.305907\n",
      "[1000]\tvalid_0's rmse: 0.300157\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.299769:  40%|####      | 8/20 [10:11<13:30, 67.52s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.299769:  45%|####5     | 9/20 [10:11<12:12, 66.55s/it]\u001b[A\u001b[32m[I 2021-06-29 12:37:52,488]\u001b[0m Trial 48 finished with value: 0.30015701020261865 and parameters: {'lambda_l1': 0.0005527971893118149, 'lambda_l2': 0.5462821994012003}. Best is trial 45 with value: 0.29976875646604645.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.299769:  45%|####5     | 9/20 [10:11<12:12, 66.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335522\n",
      "[400]\tvalid_0's rmse: 0.322693\n",
      "[600]\tvalid_0's rmse: 0.313495\n",
      "[800]\tvalid_0's rmse: 0.306422\n",
      "[1000]\tvalid_0's rmse: 0.301047\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.301047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.299769:  45%|####5     | 9/20 [11:27<12:12, 66.55s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.299769:  50%|#####     | 10/20 [11:27<11:33, 69.37s/it]\u001b[A\u001b[32m[I 2021-06-29 12:39:08,196]\u001b[0m Trial 49 finished with value: 0.30104686872464326 and parameters: {'lambda_l1': 6.417837385461244e-07, 'lambda_l2': 3.4064082271260885}. Best is trial 45 with value: 0.29976875646604645.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.299769:  50%|#####     | 10/20 [11:27<11:33, 69.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.340914\n",
      "[400]\tvalid_0's rmse: 0.330537\n",
      "[600]\tvalid_0's rmse: 0.323203\n",
      "[800]\tvalid_0's rmse: 0.317578\n",
      "[1000]\tvalid_0's rmse: 0.313123\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.313123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.299769:  50%|#####     | 10/20 [13:08<11:33, 69.37s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.299769:  55%|#####5    | 11/20 [13:08<11:52, 79.15s/it]\u001b[A\u001b[32m[I 2021-06-29 12:40:49,504]\u001b[0m Trial 50 finished with value: 0.3131232310364122 and parameters: {'lambda_l1': 9.53287224350867, 'lambda_l2': 1.9746080082486007e-08}. Best is trial 45 with value: 0.29976875646604645.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.299769:  55%|#####5    | 11/20 [13:08<11:52, 79.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335089\n",
      "[400]\tvalid_0's rmse: 0.322354\n",
      "[600]\tvalid_0's rmse: 0.312986\n",
      "[800]\tvalid_0's rmse: 0.305621\n",
      "[1000]\tvalid_0's rmse: 0.300097\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.299769:  55%|#####5    | 11/20 [14:25<11:52, 79.15s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.299769:  60%|######    | 12/20 [14:25<10:27, 78.49s/it]\u001b[A\u001b[32m[I 2021-06-29 12:42:06,471]\u001b[0m Trial 51 finished with value: 0.30009689024311176 and parameters: {'lambda_l1': 1.9934363984572498, 'lambda_l2': 0.016710148132586977}. Best is trial 45 with value: 0.29976875646604645.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.299769:  60%|######    | 12/20 [14:25<10:27, 78.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.334692\n",
      "[400]\tvalid_0's rmse: 0.321741\n",
      "[600]\tvalid_0's rmse: 0.311899\n",
      "[800]\tvalid_0's rmse: 0.30459\n",
      "[1000]\tvalid_0's rmse: 0.298901\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.298901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.298901:  60%|######    | 12/20 [15:30<10:27, 78.49s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.298901:  65%|######5   | 13/20 [15:30<08:41, 74.52s/it]\u001b[A\u001b[32m[I 2021-06-29 12:43:11,865]\u001b[0m Trial 52 finished with value: 0.298900571878056 and parameters: {'lambda_l1': 0.6590362055599431, 'lambda_l2': 0.009813944627065432}. Best is trial 52 with value: 0.298900571878056.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.298901:  65%|######5   | 13/20 [15:30<08:41, 74.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.334849\n",
      "[400]\tvalid_0's rmse: 0.321626\n",
      "[600]\tvalid_0's rmse: 0.311974\n",
      "[800]\tvalid_0's rmse: 0.30428\n",
      "[1000]\tvalid_0's rmse: 0.29844\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.29844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.298440:  65%|######5   | 13/20 [16:49<08:41, 74.52s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.298440:  70%|#######   | 14/20 [16:49<07:34, 75.73s/it]\u001b[A\u001b[32m[I 2021-06-29 12:44:30,409]\u001b[0m Trial 53 finished with value: 0.29844000999893006 and parameters: {'lambda_l1': 0.5263404867949211, 'lambda_l2': 0.006584498723266508}. Best is trial 53 with value: 0.29844000999893006.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.298440:  70%|#######   | 14/20 [16:49<07:34, 75.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008161 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.334766\n",
      "[400]\tvalid_0's rmse: 0.321624\n",
      "[600]\tvalid_0's rmse: 0.312184\n",
      "[800]\tvalid_0's rmse: 0.30488\n",
      "[1000]\tvalid_0's rmse: 0.299167\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.299167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.298440:  70%|#######   | 14/20 [18:00<07:34, 75.73s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.298440:  75%|#######5  | 15/20 [18:00<06:11, 74.34s/it]\u001b[A\u001b[32m[I 2021-06-29 12:45:41,506]\u001b[0m Trial 54 finished with value: 0.29916740948463066 and parameters: {'lambda_l1': 0.979735235544393, 'lambda_l2': 0.006650090931780751}. Best is trial 53 with value: 0.29844000999893006.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.298440:  75%|#######5  | 15/20 [18:00<06:11, 74.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.334668\n",
      "[400]\tvalid_0's rmse: 0.321704\n",
      "[600]\tvalid_0's rmse: 0.312092\n",
      "[800]\tvalid_0's rmse: 0.304729\n",
      "[1000]\tvalid_0's rmse: 0.299289\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.299289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.298440:  75%|#######5  | 15/20 [19:10<06:11, 74.34s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.298440:  80%|########  | 16/20 [19:10<04:51, 72.97s/it]\u001b[A\u001b[32m[I 2021-06-29 12:46:51,312]\u001b[0m Trial 55 finished with value: 0.29928856152107913 and parameters: {'lambda_l1': 0.7960241410399973, 'lambda_l2': 3.5532510106141136e-05}. Best is trial 53 with value: 0.29844000999893006.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.298440:  80%|########  | 16/20 [19:10<04:51, 72.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.340405\n",
      "[400]\tvalid_0's rmse: 0.329726\n",
      "[600]\tvalid_0's rmse: 0.322153\n",
      "[800]\tvalid_0's rmse: 0.316145\n",
      "[1000]\tvalid_0's rmse: 0.311358\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.311358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.298440:  80%|########  | 16/20 [20:45<04:51, 72.97s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.298440:  85%|########5 | 17/20 [20:45<03:58, 79.61s/it]\u001b[A\u001b[32m[I 2021-06-29 12:48:26,366]\u001b[0m Trial 56 finished with value: 0.31135789012455733 and parameters: {'lambda_l1': 7.915943711786655, 'lambda_l2': 9.314315257842672}. Best is trial 53 with value: 0.29844000999893006.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.298440:  85%|########5 | 17/20 [20:45<03:58, 79.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335492\n",
      "[400]\tvalid_0's rmse: 0.322036\n",
      "[600]\tvalid_0's rmse: 0.312787\n",
      "[800]\tvalid_0's rmse: 0.305838\n",
      "[1000]\tvalid_0's rmse: 0.300367\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.300367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.298440:  85%|########5 | 17/20 [21:54<03:58, 79.61s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.298440:  90%|######### | 18/20 [21:54<02:33, 76.64s/it]\u001b[A\u001b[32m[I 2021-06-29 12:49:36,095]\u001b[0m Trial 57 finished with value: 0.3003671038959091 and parameters: {'lambda_l1': 1.5723994481053976e-05, 'lambda_l2': 0.005831460399662883}. Best is trial 53 with value: 0.29844000999893006.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.298440:  90%|######### | 18/20 [21:54<02:33, 76.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335069\n",
      "[400]\tvalid_0's rmse: 0.322298\n",
      "[600]\tvalid_0's rmse: 0.312781\n",
      "[800]\tvalid_0's rmse: 0.305401\n",
      "[1000]\tvalid_0's rmse: 0.299943\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.299943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.298440:  90%|######### | 18/20 [23:01<02:33, 76.64s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.298440:  95%|#########5| 19/20 [23:01<01:13, 73.69s/it]\u001b[A\u001b[32m[I 2021-06-29 12:50:42,898]\u001b[0m Trial 58 finished with value: 0.2999428905198749 and parameters: {'lambda_l1': 0.23417204028703256, 'lambda_l2': 0.0012268708262154456}. Best is trial 53 with value: 0.29844000999893006.\u001b[0m\n",
      "\n",
      "regularization_factors, val_score: 0.298440:  95%|#########5| 19/20 [23:01<01:13, 73.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.339264\n",
      "[400]\tvalid_0's rmse: 0.328196\n",
      "[600]\tvalid_0's rmse: 0.320327\n",
      "[800]\tvalid_0's rmse: 0.314325\n",
      "[1000]\tvalid_0's rmse: 0.309601\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.309601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.298440:  95%|#########5| 19/20 [24:37<01:13, 73.69s/it]\u001b[A\n",
      "regularization_factors, val_score: 0.298440: 100%|##########| 20/20 [24:37<00:00, 80.44s/it]\u001b[A\u001b[32m[I 2021-06-29 12:52:19,080]\u001b[0m Trial 59 finished with value: 0.3096006425674605 and parameters: {'lambda_l1': 7.43460584737166, 'lambda_l2': 0.04638533736575926}. Best is trial 53 with value: 0.29844000999893006.\u001b[0m\n",
      "regularization_factors, val_score: 0.298440: 100%|##########| 20/20 [24:37<00:00, 73.90s/it]\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.298440:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.336409\n",
      "[400]\tvalid_0's rmse: 0.323443\n",
      "[600]\tvalid_0's rmse: 0.314445\n",
      "[800]\tvalid_0's rmse: 0.307319\n",
      "[1000]\tvalid_0's rmse: 0.301821\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.301821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "min_data_in_leaf, val_score: 0.298440:   0%|          | 0/5 [01:13<?, ?it/s]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.298440:  20%|##        | 1/5 [01:13<04:54, 73.53s/it]\u001b[A\u001b[32m[I 2021-06-29 12:53:33,155]\u001b[0m Trial 60 finished with value: 0.301821259453703 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.301821259453703.\u001b[0m\n",
      "\n",
      "min_data_in_leaf, val_score: 0.298440:  20%|##        | 1/5 [01:13<04:54, 73.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335022\n",
      "[400]\tvalid_0's rmse: 0.321974\n",
      "[600]\tvalid_0's rmse: 0.312517\n",
      "[800]\tvalid_0's rmse: 0.305177\n",
      "[1000]\tvalid_0's rmse: 0.299567\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.299567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "min_data_in_leaf, val_score: 0.298440:  20%|##        | 1/5 [02:22<04:54, 73.53s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.298440:  40%|####      | 2/5 [02:22<03:33, 71.06s/it]\u001b[A\u001b[32m[I 2021-06-29 12:54:42,483]\u001b[0m Trial 61 finished with value: 0.2995665970201885 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 0.2995665970201885.\u001b[0m\n",
      "\n",
      "min_data_in_leaf, val_score: 0.298440:  40%|####      | 2/5 [02:22<03:33, 71.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.33429\n",
      "[400]\tvalid_0's rmse: 0.321462\n",
      "[600]\tvalid_0's rmse: 0.312016\n",
      "[800]\tvalid_0's rmse: 0.30471\n",
      "[1000]\tvalid_0's rmse: 0.299136\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.299136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "min_data_in_leaf, val_score: 0.298440:  40%|####      | 2/5 [03:30<03:33, 71.06s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.298440:  60%|######    | 3/5 [03:30<02:18, 69.40s/it]\u001b[A\u001b[32m[I 2021-06-29 12:55:49,911]\u001b[0m Trial 62 finished with value: 0.2991363512168902 and parameters: {'min_child_samples': 10}. Best is trial 62 with value: 0.2991363512168902.\u001b[0m\n",
      "\n",
      "min_data_in_leaf, val_score: 0.298440:  60%|######    | 3/5 [03:30<02:18, 69.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.338169\n",
      "[400]\tvalid_0's rmse: 0.32548\n",
      "[600]\tvalid_0's rmse: 0.316197\n",
      "[800]\tvalid_0's rmse: 0.309171\n",
      "[1000]\tvalid_0's rmse: 0.303453\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.303453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "min_data_in_leaf, val_score: 0.298440:  60%|######    | 3/5 [04:58<02:18, 69.40s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.298440:  80%|########  | 4/5 [04:58<01:16, 76.74s/it]\u001b[A\u001b[32m[I 2021-06-29 12:57:17,900]\u001b[0m Trial 63 finished with value: 0.3034529698245187 and parameters: {'min_child_samples': 100}. Best is trial 62 with value: 0.2991363512168902.\u001b[0m\n",
      "\n",
      "min_data_in_leaf, val_score: 0.298440:  80%|########  | 4/5 [04:58<01:16, 76.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006858 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4339\n",
      "[LightGBM] [Info] Number of data points in the train set: 520901, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 0.023188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.333573\n",
      "[400]\tvalid_0's rmse: 0.320515\n",
      "[600]\tvalid_0's rmse: 0.311475\n",
      "[800]\tvalid_0's rmse: 0.303706\n",
      "[1000]\tvalid_0's rmse: 0.298169\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.298169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "min_data_in_leaf, val_score: 0.298169:  80%|########  | 4/5 [06:09<01:16, 76.74s/it]\u001b[A\n",
      "min_data_in_leaf, val_score: 0.298169: 100%|##########| 5/5 [06:09<00:00, 74.90s/it]\u001b[A\u001b[32m[I 2021-06-29 12:58:29,526]\u001b[0m Trial 64 finished with value: 0.2981692288594475 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.2981692288594475.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.298169: 100%|##########| 5/5 [06:09<00:00, 73.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Params: \n",
      "    objective: regression\n",
      "    metric: rmse\n",
      "    random_seed: 0\n",
      "    feature_pre_filter: False\n",
      "    lambda_l1: 0.5263404867949211\n",
      "    lambda_l2: 0.006584498723266508\n",
      "    num_leaves: 252\n",
      "    feature_fraction: 1.0\n",
      "    bagging_fraction: 0.7850836052089633\n",
      "    bagging_freq: 3\n",
      "    min_child_samples: 5\n",
      "    num_iterations: 1000\n",
      "    early_stopping_round: 100\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'r2_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2955df656ca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mlight_gbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2955df656ca6>\u001b[0m in \u001b[0;36mlight_gbm\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# 評価スコアの計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mr2_trainval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trainval_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mr2_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r2_score' is not defined"
     ]
    }
   ],
   "source": [
    "# !pip install optuna\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as lgb\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Scikit-learn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    " \n",
    "import joblib\n",
    "import operator\n",
    "# visualize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "# from matplotlib_venn import venn2, venn3\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "# 他ファイルのインポート・リロード\n",
    "import imp\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "\n",
    "def light_gbm():\n",
    "      #全時系列データの呼び出し\n",
    "    model_stock = 'sandp500'\n",
    "    path = '../../../stock_data/stock_code/{}.csv'.format(model_stock)\n",
    "    path = '/Users/suzukiryotaro/Desktop/python_stock/stock_data/stock_code/sandp500.csv'\n",
    "    data = pd.read_csv(path)\n",
    "    print(data)\n",
    "\n",
    "    # 作業ディレクトリの移動と確認\n",
    "    os.chdir('/Users/suzukiryotaro/Desktop/python_stock/machine_learning/XGBboost/model1/model')\n",
    "    !ls\n",
    "    # 他ファイルのインポート・リロード\n",
    "    import data_process\n",
    "    imp.reload(data_process)\n",
    "    \n",
    "    \n",
    "    preprocess_data = pd.DataFrame()\n",
    "    count = 0\n",
    "    for  file in data['symbol'] :\n",
    "        count = count +1\n",
    "        print(count)\n",
    "        print(file)\n",
    "        try:\n",
    "            df = yf.download(file, start='2014-01-01',end='2020-01-01')\n",
    "            df = data_process.create_data(df)\n",
    "#             print(df)\n",
    "            preprocess_data = preprocess_data.append(df)\n",
    "\n",
    "        except: \n",
    "            print('errror')\n",
    "            continue\n",
    "\n",
    "    save_path = '/Users/suzukiryotaro/Desktop/python_stock/machine_learning/ansamble/lightgbm/preprocss_data.csv'\n",
    "#     preprocess_data.to_csv(save_path)\n",
    "\n",
    "    df = pd.read_csv(save_path, index_col=0)\n",
    "    \n",
    "#     print(df)\n",
    "    #選択する特徴量\n",
    "    cols =  ['return','sma210'\n",
    "\n",
    "            ,'ratio_sma75_30', 'ratio_sma75_150', 'ratio_sma105_30', \n",
    "            'ratio_sma105_150', 'ratio_sma135_150'\n",
    "            ,'Highest161','adosc', 'sma10', \n",
    "          'adosc-SG' ,'typical-price',\"ema270\"\n",
    "       ,'Highest121','Highest45,81days_ago',\n",
    "\n",
    "    'today_by_sma30ratio','today_by_sma45ratio','today_by_sma60ratio','today_by_sma120ratio'\n",
    "\n",
    "\n",
    "           ]\n",
    "    df = df[cols]\n",
    "    df = df.set_axis([\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",'h','i','j','k','l','m','n','o','p','q','r','s'], axis=1)\n",
    "#     print(df)\n",
    "\n",
    "    X = df.copy()\n",
    "    y = X.pop('a')\n",
    "    X.reindex(columns=[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",'h','i','j','k','l','m','n','o','p','q','r'])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=11)\n",
    "    # train用・valid用のデータセットを生成する\n",
    "    train = lgb.Dataset(X_train, y_train)\n",
    "    val = lgb.Dataset(X_val, y_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ハイパーパラメータサーチ&モデル構築\n",
    "    params = {'objective': 'regression',\n",
    "              'metric': 'rmse',\n",
    "              'random_seed':0} \n",
    "\n",
    "    gbm_o = lgb.train(params,\n",
    "                        train,\n",
    "                        valid_sets=val,\n",
    "                        early_stopping_rounds=100,\n",
    "                        verbose_eval=200,)\n",
    "\n",
    "    # 調整後モデルで予測の実行\n",
    "    y_trainval_pred = gbm_o.predict(X_train,num_iteration=gbm_o.best_iteration)\n",
    "    y_test_pred = gbm_o.predict(X_val,num_iteration=gbm_o.best_iteration)\n",
    "\n",
    "    # ベストパラメータの取得\n",
    "    best_params = gbm_o.params\n",
    "    print(\"  Params: \")\n",
    "    for key, value in best_params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    # 評価スコアの計算\n",
    "    r2_trainval = r2_score(y_train, y_trainval_pred)\n",
    "    r2_test = r2_score(y_val, y_test_pred)\n",
    "\n",
    "    print(\"r2_train:{0:.4}\".format(r2_trainval))\n",
    "    print(\"r2_test:{0:.4}\".format(r2_test))\n",
    "\n",
    "    \n",
    "light_gbm()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     # ベストなパラメータ、途中経過を保存する\n",
    "#     best_params, tuning_history = dict(), list() \n",
    "\n",
    "#     # Model\n",
    "#     model = lgb.LGBMRegressor()\n",
    "\n",
    "#     lgbm_params = {'objective': 'regression', \n",
    "#                'learning_rate':0.01, \n",
    "#                'num_boost_round':10000, \n",
    "#                'early_stopping_rounds':10\n",
    "#               }\n",
    "\n",
    "#     # 学習\n",
    "#     model = lgb.train(lgbm_params, \n",
    "#                       lgb_train, \n",
    "#                       valid_sets=lgb_val, \n",
    "#                       verbose_eval=0,\n",
    "#                       early_stopping_rounds=100\n",
    "#                      ) \n",
    "#     best.params\n",
    "#     best.best_iteration\n",
    "#     best.best_score\n",
    "\n",
    "# light_gbm()\n",
    "#     #  print(best_params)\n",
    "#     #  print(tuning_history)\n",
    "#     # # パラメーター設定\n",
    "#     # light_params = {\"max_depth\": 20,\n",
    "#     #                 'task': 'train', # レーニング ⇔　予測predict\n",
    "#     #                 'boosting_type': 'gbdt', # 勾配ブースティング\n",
    "#     #                 'objective': 'reg:squarederror', # 目的関数：多値分類、マルチクラス分類 \n",
    "#     #                 'metric': \"rmse\", # 検証用データセットで、分類モデルの性能を測る指標 \n",
    "#     #                 'num_class': 2, # 目的変数のクラス数 \n",
    "#     #                 'num_leaves': 23, # 決定木の複雑度を調整（初期値31）\n",
    "#     #                 'min_data_in_leaf': 15, # データの最小数（初期値20） \n",
    "#     #                 \"learning_rate\": 0.025400643228660445,\n",
    "#     #                 'gamma':0.20387750446308275, \n",
    "#     #               } \n",
    "\n",
    "\n",
    "\n",
    "#     # # fit\n",
    "#     # model.fit(params,\n",
    "#     #     X_train, y_train, \n",
    "#     #     eval_set=[(X_valid, y_valid)], \n",
    "#     #     verbose=100, \n",
    "#     #     num_boost_round=100,\n",
    "#     #     best_params=best_params,\n",
    "#     #     early_stopping_rounds=300,\n",
    "#     # )\n",
    "\n",
    "#     # model = lgb.train( trains, valid_sets=valids,\n",
    "#     #                   verbose_eval=False,\n",
    "\n",
    "#     #                   early_stopping_rounds=5,\n",
    "\n",
    "#     #                   tuning_history=history)\n",
    "#     # joblib.dump(model, '/content/drive/MyDrive/machine_learning/ansamble/model/lightgbm.joblib') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df8cc4f-feaf-4810-a320-b536ec2b9f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
