{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24389c0-5303-48aa-954e-c88a3cb23725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (2.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from optuna) (20.9)\n",
      "Requirement already satisfied: cliff in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from optuna) (3.8.0)\n",
      "Requirement already satisfied: scipy!=1.4.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from optuna) (1.6.3)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from optuna) (5.0.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from optuna) (1.4.19)\n",
      "Requirement already satisfied: cmaes>=0.8.2 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from optuna) (0.8.2)\n",
      "Requirement already satisfied: alembic in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from optuna) (1.6.5)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from optuna) (4.61.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from optuna) (1.19.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from sqlalchemy>=1.1.0->optuna) (1.1.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from sqlalchemy>=1.1.0->optuna) (3.10.0)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from alembic->optuna) (1.1.4)\n",
      "Requirement already satisfied: python-editor>=0.3 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from alembic->optuna) (1.0.4)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from alembic->optuna) (2.8.1)\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from cliff->optuna) (2.1.0)\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from cliff->optuna) (3.3.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from cliff->optuna) (5.6.0)\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from cliff->optuna) (2.1.1)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from cliff->optuna) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: colorama>=0.3.7 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n",
      "Requirement already satisfied: pyperclip>=1.6 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/py37/lib/python3.7/site-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
      "    symbol                 Name                  Sector\n",
      "0      MMM           3M Company             Industrials\n",
      "1      AOS      A.O. Smith Corp             Industrials\n",
      "2      ABT  Abbott Laboratories             Health Care\n",
      "3     ABBV          AbbVie Inc.             Health Care\n",
      "4     ABMD              Abiomed             Health Care\n",
      "..     ...                  ...                     ...\n",
      "500    YUM      Yum! Brands Inc  Consumer Discretionary\n",
      "501   ZBRA   Zebra Technologies  Information Technology\n",
      "502    ZBH        Zimmer Biomet             Health Care\n",
      "503   ZION        Zions Bancorp              Financials\n",
      "504    ZTS               Zoetis             Health Care\n",
      "\n",
      "[505 rows x 3 columns]\n",
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2016-01-06  145.589996  145.759995  143.419998  144.490005  122.994637   \n",
      "2016-01-07  142.520004  143.130005  140.630005  140.970001  119.998299   \n",
      "2016-01-08  141.360001  142.500000  140.220001  140.490005  119.589722   \n",
      "2016-01-11  140.970001  141.429993  139.410004  140.460007  119.564194   \n",
      "2016-01-12  141.360001  142.149994  139.130005  140.860001  119.904678   \n",
      "...                ...         ...         ...         ...         ...   \n",
      "2020-12-24  159.919998  161.869995  159.850006  160.720001  160.232651   \n",
      "2020-12-28  161.440002  162.830002  160.309998  162.389999  161.897583   \n",
      "2020-12-29  163.210007  165.100006  162.399994  163.119995  162.625381   \n",
      "2020-12-30  163.509995  164.800003  163.160004  164.270004  163.771881   \n",
      "2020-12-31  164.500000  165.679993  163.229996  165.500000  164.998169   \n",
      "\n",
      "               Volume    return       sma10  typical-price         adosc  ...  \\\n",
      "Date                                                                      ...   \n",
      "2016-01-06  2997100.0 -0.407529  130.308143     144.556666  2.357614e+07  ...   \n",
      "2016-01-07  3553500.0  0.014886  129.806484     141.576670  2.098918e+07  ...   \n",
      "2016-01-08  2664000.0 -0.128950  129.316742     141.070002  1.895613e+07  ...   \n",
      "2016-01-11  2775500.0 -0.148470  128.829556     140.433334  1.906608e+07  ...   \n",
      "2016-01-12  2363500.0 -0.280776  128.343502     140.713333  1.941043e+07  ...   \n",
      "...               ...       ...         ...            ...           ...  ...   \n",
      "2020-12-24   417400.0  0.176996  161.040525     160.813334  2.564110e+08  ...   \n",
      "2020-12-28  1522400.0  0.143070  160.947474     161.843333  2.574018e+08  ...   \n",
      "2020-12-29  1188400.0  0.244055  160.859077     163.539998  2.568472e+08  ...   \n",
      "2020-12-30  1009000.0  0.164824  160.825180     164.076670  2.572040e+08  ...   \n",
      "2020-12-31  1292600.0  0.156472  160.827507     164.803329  2.583067e+08  ...   \n",
      "\n",
      "            today_by_high_low_ratio_300_sma_ratio  Volume_5daysago_ratio  \\\n",
      "Date                                                                       \n",
      "2016-01-06                            9285.960665               1.642517   \n",
      "2016-01-07                            9043.403661               2.288005   \n",
      "2016-01-08                            8999.060734               1.657644   \n",
      "2016-01-11                            9000.498467               0.846912   \n",
      "2016-01-12                            8997.469536               0.879246   \n",
      "...                                           ...                    ...   \n",
      "2020-12-24                            6385.791691               0.280737   \n",
      "2020-12-28                            6450.181283               0.426873   \n",
      "2020-12-29                            6482.922058               0.811860   \n",
      "2020-12-30                            6553.057203               0.834436   \n",
      "2020-12-31                            6603.151376               1.109909   \n",
      "\n",
      "            Volume_10daysago_ratio  Volume_15daysago_ratio  \\\n",
      "Date                                                         \n",
      "2016-01-06                1.311986                0.865663   \n",
      "2016-01-07                1.405268                0.411004   \n",
      "2016-01-08                1.202546                0.558011   \n",
      "2016-01-11                3.271452                0.908838   \n",
      "2016-01-12                1.853435                0.412018   \n",
      "...                            ...                     ...   \n",
      "2020-12-24                0.225988                0.180834   \n",
      "2020-12-28                1.204430                1.016899   \n",
      "2020-12-29                0.736809                0.844574   \n",
      "2020-12-30                0.556505                0.633038   \n",
      "2020-12-31                0.897078                0.855800   \n",
      "\n",
      "            Volume_20daysago_ratio  Volume_40daysago_ratio  \\\n",
      "Date                                                         \n",
      "2016-01-06                1.398684                1.611344   \n",
      "2016-01-07                1.511870                1.467782   \n",
      "2016-01-08                1.001203                1.357176   \n",
      "2016-01-11                1.087919                1.101870   \n",
      "2016-01-12                0.936707                1.025113   \n",
      "...                            ...                     ...   \n",
      "2020-12-24                0.210617                0.193178   \n",
      "2020-12-28                1.784132                0.989214   \n",
      "2020-12-29                0.262114                0.571814   \n",
      "2020-12-30                0.513643                0.665304   \n",
      "2020-12-31                0.845168                0.850675   \n",
      "\n",
      "            Volume_61daysago_ratio  Volume_81daysago_ratio  \\\n",
      "Date                                                         \n",
      "2016-01-06                1.491985                1.475532   \n",
      "2016-01-07                1.549041                1.418450   \n",
      "2016-01-08                1.863849                1.169858   \n",
      "2016-01-11                1.368860                1.031478   \n",
      "2016-01-12                1.045658                1.147163   \n",
      "...                            ...                     ...   \n",
      "2020-12-24                0.398930                0.299684   \n",
      "2020-12-28                0.798448                1.195821   \n",
      "2020-12-29                1.119126                0.663836   \n",
      "2020-12-30                0.967773                0.562399   \n",
      "2020-12-31                1.014122                0.832593   \n",
      "\n",
      "            Volume_121daysago_ratio  Volume_161daysago_ratio  \n",
      "Date                                                          \n",
      "2016-01-06                 1.678014                 1.714784  \n",
      "2016-01-07                 1.755769                 1.712448  \n",
      "2016-01-08                 1.096748                 1.346747  \n",
      "2016-01-11                 1.181567                 1.156073  \n",
      "2016-01-12                 0.861365                 1.296703  \n",
      "...                             ...                      ...  \n",
      "2020-12-24                 0.321621                 0.134732  \n",
      "2020-12-28                 1.335087                 0.941206  \n",
      "2020-12-29                 1.274287                 0.629349  \n",
      "2020-12-30                 1.048312                 0.534004  \n",
      "2020-12-31                 0.709791                 0.687919  \n",
      "\n",
      "[620151 rows x 215 columns]\n",
      "              sma210  ratio_sma75_30  ratio_sma75_150  ratio_sma105_30  \\\n",
      "Date                                                                     \n",
      "2016-01-06 -0.058017       -0.113448         0.084709        -0.279536   \n",
      "2016-01-07 -0.056462       -0.073627         0.093189        -0.245671   \n",
      "2016-01-08 -0.056371       -0.033076         0.102692        -0.214199   \n",
      "2016-01-11 -0.064880        0.007874         0.112294        -0.180988   \n",
      "2016-01-12 -0.058376        0.049470         0.122329        -0.147384   \n",
      "...              ...             ...              ...              ...   \n",
      "2020-12-24  0.089651        0.036454         0.517724        -0.045500   \n",
      "2020-12-28  0.097391        0.045963         0.506934        -0.030905   \n",
      "2020-12-29  0.081174        0.055391         0.498395        -0.017047   \n",
      "2020-12-30  0.090307        0.060495         0.489508        -0.007398   \n",
      "2020-12-31  0.073488        0.063178         0.480500        -0.000940   \n",
      "\n",
      "            ratio_sma105_150  ratio_sma135_150  Highest161         adosc  \\\n",
      "Date                                                                       \n",
      "2016-01-06         -0.084709         -0.043445    0.903492  2.357614e+07   \n",
      "2016-01-07         -0.081746         -0.043044    0.881672  2.098918e+07   \n",
      "2016-01-08         -0.080899         -0.043793    0.878670  1.895613e+07   \n",
      "2016-01-11         -0.078539         -0.043226    0.883674  1.906608e+07   \n",
      "2016-01-12         -0.075953         -0.042638    0.886191  1.941043e+07   \n",
      "...                      ...               ...         ...           ...   \n",
      "2020-12-24          0.431840          0.120932    0.921824  2.564110e+08   \n",
      "2020-12-28          0.426540          0.119542    0.931402  2.574018e+08   \n",
      "2020-12-29          0.422767          0.120183    0.935589  2.568472e+08   \n",
      "2020-12-30          0.418720          0.121655    0.942185  2.572040e+08   \n",
      "2020-12-31          0.413722          0.123731    0.949240  2.583067e+08   \n",
      "\n",
      "                 sma10  adoscSG  ...  Highest121  Highest4581days_ago  \\\n",
      "Date                             ...                                    \n",
      "2016-01-06  130.308143       -1  ...    0.909028             0.931803   \n",
      "2016-01-07  129.806484       -1  ...    0.886883             0.909103   \n",
      "2016-01-08  129.316742       -1  ...    0.883863             0.906007   \n",
      "2016-01-11  128.829556       -1  ...    0.883674             0.905814   \n",
      "2016-01-12  128.343502       -1  ...    0.886191             0.908394   \n",
      "...                ...      ...  ...         ...                  ...   \n",
      "2020-12-24  161.040525        1  ...    0.921824             0.997466   \n",
      "2020-12-28  160.947474        1  ...    0.931402             1.007830   \n",
      "2020-12-29  160.859077        1  ...    0.935589             1.007863   \n",
      "2020-12-30  160.825180        1  ...    0.942185             0.994832   \n",
      "2020-12-31  160.827507        1  ...    0.949240             1.002281   \n",
      "\n",
      "            today_by_sma30ratio  today_by_sma45ratio  today_by_sma60ratio  \\\n",
      "Date                                                                        \n",
      "2016-01-06          -391.856412        -7.324275e+02         -2562.204106   \n",
      "2016-01-07          -311.700642        -4.658841e+02         -1365.213727   \n",
      "2016-01-08          -316.973766        -4.814504e+02         -1441.817980   \n",
      "2016-01-11          -317.366063        -4.749401e+02         -1598.076378   \n",
      "2016-01-12          -317.809692        -4.840034e+02         -1500.333833   \n",
      "...                         ...                  ...                  ...   \n",
      "2020-12-24         -1837.240383        -2.545224e+04         -3517.540985   \n",
      "2020-12-28         -2801.922916         1.185379e+06        -11000.177444   \n",
      "2020-12-29         -2960.969285        -3.211477e+04        -70286.041665   \n",
      "2020-12-30         -7771.861263         3.157059e+03         15585.393484   \n",
      "2020-12-31        114036.336786         3.980535e+03          3846.507923   \n",
      "\n",
      "            today_by_sma120ratio  Adjclose_today_20daysago_ratio  \\\n",
      "Date                                                               \n",
      "2016-01-06          -2079.934558                        0.915943   \n",
      "2016-01-07          -1574.494011                        0.899101   \n",
      "2016-01-08          -1470.328463                        0.900289   \n",
      "2016-01-11          -1614.639018                        0.891696   \n",
      "2016-01-12          -1714.756789                        0.909772   \n",
      "...                          ...                             ...   \n",
      "2020-12-24           1344.117114                        1.003309   \n",
      "2020-12-28           1285.833586                        1.005698   \n",
      "2020-12-29           1200.172881                        1.017084   \n",
      "2020-12-30           1134.294178                        1.018034   \n",
      "2020-12-31           1143.473238                        1.041208   \n",
      "\n",
      "            Adjclose_today_15daysago_ratio  Adjclose_today_10daysago_ratio  \\\n",
      "Date                                                                         \n",
      "2016-01-06                        0.916641                        0.979726   \n",
      "2016-01-07                        0.951664                        0.946298   \n",
      "2016-01-08                        0.936913                        0.929413   \n",
      "2016-01-11                        0.943635                        0.929030   \n",
      "2016-01-12                        0.958753                        0.931491   \n",
      "...                                    ...                             ...   \n",
      "2020-12-24                        1.023238                        1.016443   \n",
      "2020-12-28                        1.028110                        1.017928   \n",
      "2020-12-29                        1.029473                        1.022696   \n",
      "2020-12-30                        1.033210                        1.014263   \n",
      "2020-12-31                        1.042848                        1.030382   \n",
      "\n",
      "            Adjclose_today_5daysago_ratio  \n",
      "Date                                       \n",
      "2016-01-06                       0.945059  \n",
      "2016-01-07                       0.927984  \n",
      "2016-01-08                       0.932621  \n",
      "2016-01-11                       0.956682  \n",
      "2016-01-12                       0.955242  \n",
      "...                                   ...  \n",
      "2020-12-24                       0.987830  \n",
      "2020-12-28                       0.992422  \n",
      "2020-12-29                       1.014176  \n",
      "2020-12-30                       1.015078  \n",
      "2020-12-31                       1.035346  \n",
      "\n",
      "[620151 rows x 22 columns]\n",
      "Date\n",
      "2016-01-06   -0.407529\n",
      "2016-01-07    0.014886\n",
      "2016-01-08   -0.128950\n",
      "2016-01-11   -0.148470\n",
      "2016-01-12   -0.280776\n",
      "                ...   \n",
      "2020-12-24    0.176996\n",
      "2020-12-28    0.143070\n",
      "2020-12-29    0.244055\n",
      "2020-12-30    0.164824\n",
      "2020-12-31    0.156472\n",
      "Name: return, Length: 620151, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-09 11:25:34,996]\u001b[0m A new study created in memory with name: no-name-7b74419a-6c6d-40ec-867c-9c7baef2b094\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5358\n",
      "[LightGBM] [Info] Number of data points in the train set: 434105, number of used features: 22\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Info] Start training from score 0.027948\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.451657\n",
      "[400]\tvalid_0's rmse: 0.446728\n",
      "[600]\tvalid_0's rmse: 0.443148\n",
      "[800]\tvalid_0's rmse: 0.440664\n",
      "[1000]\tvalid_0's rmse: 0.438566\n",
      "[1200]\tvalid_0's rmse: 0.436669\n",
      "[1400]\tvalid_0's rmse: 0.435029\n",
      "[1600]\tvalid_0's rmse: 0.433572\n",
      "[1800]\tvalid_0's rmse: 0.432121\n",
      "[2000]\tvalid_0's rmse: 0.430886\n",
      "[2200]\tvalid_0's rmse: 0.429708\n",
      "[2400]\tvalid_0's rmse: 0.428641\n",
      "[2600]\tvalid_0's rmse: 0.427599\n",
      "[2800]\tvalid_0's rmse: 0.426624\n",
      "[3000]\tvalid_0's rmse: 0.425786\n",
      "[3200]\tvalid_0's rmse: 0.424948\n",
      "[3400]\tvalid_0's rmse: 0.424126\n",
      "[3600]\tvalid_0's rmse: 0.42335\n",
      "[3800]\tvalid_0's rmse: 0.422587\n",
      "[4000]\tvalid_0's rmse: 0.421907\n",
      "[4200]\tvalid_0's rmse: 0.421087\n",
      "[4400]\tvalid_0's rmse: 0.420409\n",
      "[4600]\tvalid_0's rmse: 0.419707\n",
      "[4800]\tvalid_0's rmse: 0.419048\n",
      "[5000]\tvalid_0's rmse: 0.418448\n",
      "[5200]\tvalid_0's rmse: 0.417839\n",
      "[5400]\tvalid_0's rmse: 0.417244\n",
      "[5600]\tvalid_0's rmse: 0.416662\n",
      "[5800]\tvalid_0's rmse: 0.41608\n",
      "[6000]\tvalid_0's rmse: 0.415513\n",
      "[6200]\tvalid_0's rmse: 0.414947\n",
      "[6400]\tvalid_0's rmse: 0.414443\n",
      "[6600]\tvalid_0's rmse: 0.413895\n",
      "[6800]\tvalid_0's rmse: 0.413356\n",
      "[7000]\tvalid_0's rmse: 0.41289\n",
      "[7200]\tvalid_0's rmse: 0.412434\n",
      "[7400]\tvalid_0's rmse: 0.41194\n",
      "[7600]\tvalid_0's rmse: 0.411452\n",
      "[7800]\tvalid_0's rmse: 0.410988\n",
      "[8000]\tvalid_0's rmse: 0.410516\n",
      "[8200]\tvalid_0's rmse: 0.410055\n",
      "[8400]\tvalid_0's rmse: 0.40952\n",
      "[8600]\tvalid_0's rmse: 0.409094\n",
      "[8800]\tvalid_0's rmse: 0.408683\n",
      "[9000]\tvalid_0's rmse: 0.408275\n",
      "[9200]\tvalid_0's rmse: 0.40787\n",
      "[9400]\tvalid_0's rmse: 0.407472\n",
      "[9600]\tvalid_0's rmse: 0.407069\n",
      "[9800]\tvalid_0's rmse: 0.406667\n",
      "[10000]\tvalid_0's rmse: 0.406306\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's rmse: 0.406306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:   0%|          | 0/7 [01:25<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  14%|#4        | 1/7 [01:25<08:30, 85.03s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-07-09 11:27:00,052]\u001b[0m Trial 0 finished with value: 0.40630605280755844 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.40630605280755844.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  14%|#4        | 1/7 [01:25<08:30, 85.03s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5358\n",
      "[LightGBM] [Info] Number of data points in the train set: 434105, number of used features: 22\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Info] Start training from score 0.027948\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.452896\n",
      "[400]\tvalid_0's rmse: 0.447687\n",
      "[600]\tvalid_0's rmse: 0.444505\n",
      "[800]\tvalid_0's rmse: 0.441981\n",
      "[1000]\tvalid_0's rmse: 0.439909\n",
      "[1200]\tvalid_0's rmse: 0.438108\n",
      "[1400]\tvalid_0's rmse: 0.436628\n",
      "[1600]\tvalid_0's rmse: 0.435234\n",
      "[1800]\tvalid_0's rmse: 0.433889\n",
      "[2000]\tvalid_0's rmse: 0.432739\n",
      "[2200]\tvalid_0's rmse: 0.431531\n",
      "[2400]\tvalid_0's rmse: 0.430292\n",
      "[2600]\tvalid_0's rmse: 0.429324\n",
      "[2800]\tvalid_0's rmse: 0.428338\n",
      "[3000]\tvalid_0's rmse: 0.427452\n",
      "[3200]\tvalid_0's rmse: 0.426571\n",
      "[3400]\tvalid_0's rmse: 0.425741\n",
      "[3600]\tvalid_0's rmse: 0.424969\n",
      "[3800]\tvalid_0's rmse: 0.424265\n",
      "[4000]\tvalid_0's rmse: 0.423499\n",
      "[4200]\tvalid_0's rmse: 0.422808\n",
      "[4400]\tvalid_0's rmse: 0.422135\n",
      "[4600]\tvalid_0's rmse: 0.421448\n",
      "[4800]\tvalid_0's rmse: 0.420853\n",
      "[5000]\tvalid_0's rmse: 0.420245\n",
      "[5200]\tvalid_0's rmse: 0.419585\n",
      "[5400]\tvalid_0's rmse: 0.419014\n",
      "[5600]\tvalid_0's rmse: 0.418442\n",
      "[5800]\tvalid_0's rmse: 0.41787\n",
      "[6000]\tvalid_0's rmse: 0.417337\n",
      "[6200]\tvalid_0's rmse: 0.416795\n",
      "[6400]\tvalid_0's rmse: 0.416297\n",
      "[6600]\tvalid_0's rmse: 0.415798\n",
      "[6800]\tvalid_0's rmse: 0.415265\n",
      "[7000]\tvalid_0's rmse: 0.414788\n",
      "[7200]\tvalid_0's rmse: 0.414299\n",
      "[7400]\tvalid_0's rmse: 0.413827\n",
      "[7600]\tvalid_0's rmse: 0.413415\n",
      "[7800]\tvalid_0's rmse: 0.412963\n",
      "[8000]\tvalid_0's rmse: 0.412527\n",
      "[8200]\tvalid_0's rmse: 0.412098\n",
      "[8400]\tvalid_0's rmse: 0.411649\n",
      "[8600]\tvalid_0's rmse: 0.411255\n",
      "[8800]\tvalid_0's rmse: 0.41087\n",
      "[9000]\tvalid_0's rmse: 0.410409\n",
      "[9200]\tvalid_0's rmse: 0.410021\n",
      "[9400]\tvalid_0's rmse: 0.409651\n",
      "[9600]\tvalid_0's rmse: 0.409266\n",
      "[9800]\tvalid_0's rmse: 0.408886\n",
      "[10000]\tvalid_0's rmse: 0.408485\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9999]\tvalid_0's rmse: 0.408485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  14%|#4        | 1/7 [02:47<08:30, 85.03s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  29%|##8       | 2/7 [02:47<06:56, 83.33s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-07-09 11:28:22,208]\u001b[0m Trial 1 finished with value: 0.4084850879918792 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.40630605280755844.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  29%|##8       | 2/7 [02:47<06:56, 83.33s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5358\n",
      "[LightGBM] [Info] Number of data points in the train set: 434105, number of used features: 22\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Info] Start training from score 0.027948\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.453559\n",
      "[400]\tvalid_0's rmse: 0.448298\n",
      "[600]\tvalid_0's rmse: 0.444983\n",
      "[800]\tvalid_0's rmse: 0.44259\n",
      "[1000]\tvalid_0's rmse: 0.440718\n",
      "[1200]\tvalid_0's rmse: 0.438972\n",
      "[1400]\tvalid_0's rmse: 0.437469\n",
      "[1600]\tvalid_0's rmse: 0.436123\n",
      "[1800]\tvalid_0's rmse: 0.434883\n",
      "[2000]\tvalid_0's rmse: 0.433579\n",
      "[2200]\tvalid_0's rmse: 0.432482\n",
      "[2400]\tvalid_0's rmse: 0.431321\n",
      "[2600]\tvalid_0's rmse: 0.430374\n",
      "[2800]\tvalid_0's rmse: 0.429486\n",
      "[3000]\tvalid_0's rmse: 0.428574\n",
      "[3200]\tvalid_0's rmse: 0.427808\n",
      "[3400]\tvalid_0's rmse: 0.426949\n",
      "[3600]\tvalid_0's rmse: 0.42618\n",
      "[3800]\tvalid_0's rmse: 0.425473\n",
      "[4000]\tvalid_0's rmse: 0.424711\n",
      "[4200]\tvalid_0's rmse: 0.423997\n",
      "[4400]\tvalid_0's rmse: 0.42328\n",
      "[4600]\tvalid_0's rmse: 0.422682\n",
      "[4800]\tvalid_0's rmse: 0.422078\n",
      "[5000]\tvalid_0's rmse: 0.421459\n",
      "[5200]\tvalid_0's rmse: 0.420857\n",
      "[5400]\tvalid_0's rmse: 0.420343\n",
      "[5600]\tvalid_0's rmse: 0.419774\n",
      "[5800]\tvalid_0's rmse: 0.419193\n",
      "[6000]\tvalid_0's rmse: 0.418706\n",
      "[6200]\tvalid_0's rmse: 0.418199\n",
      "[6400]\tvalid_0's rmse: 0.417689\n",
      "[6600]\tvalid_0's rmse: 0.417156\n",
      "[6800]\tvalid_0's rmse: 0.416685\n",
      "[7000]\tvalid_0's rmse: 0.416198\n",
      "[7200]\tvalid_0's rmse: 0.41572\n",
      "[7400]\tvalid_0's rmse: 0.415267\n",
      "[7600]\tvalid_0's rmse: 0.414851\n",
      "[7800]\tvalid_0's rmse: 0.414426\n",
      "[8000]\tvalid_0's rmse: 0.414029\n",
      "[8200]\tvalid_0's rmse: 0.413664\n",
      "[8400]\tvalid_0's rmse: 0.413273\n",
      "[8600]\tvalid_0's rmse: 0.412888\n",
      "[8800]\tvalid_0's rmse: 0.412517\n",
      "[9000]\tvalid_0's rmse: 0.412122\n",
      "[9200]\tvalid_0's rmse: 0.411793\n",
      "[9400]\tvalid_0's rmse: 0.411446\n",
      "[9600]\tvalid_0's rmse: 0.411087\n",
      "[9800]\tvalid_0's rmse: 0.410709\n",
      "[10000]\tvalid_0's rmse: 0.410323\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's rmse: 0.410323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  29%|##8       | 2/7 [04:10<06:56, 83.33s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  43%|####2     | 3/7 [04:10<05:32, 83.11s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-07-09 11:29:45,046]\u001b[0m Trial 2 finished with value: 0.41032291952507427 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.40630605280755844.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  43%|####2     | 3/7 [04:10<05:32, 83.11s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5358\n",
      "[LightGBM] [Info] Number of data points in the train set: 434105, number of used features: 22\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Info] Start training from score 0.027948\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.451972\n",
      "[400]\tvalid_0's rmse: 0.447096\n",
      "[600]\tvalid_0's rmse: 0.443394\n",
      "[800]\tvalid_0's rmse: 0.440879\n",
      "[1000]\tvalid_0's rmse: 0.438698\n",
      "[1200]\tvalid_0's rmse: 0.436908\n",
      "[1400]\tvalid_0's rmse: 0.435321\n",
      "[1600]\tvalid_0's rmse: 0.433864\n",
      "[1800]\tvalid_0's rmse: 0.432395\n",
      "[2000]\tvalid_0's rmse: 0.431122\n",
      "[2200]\tvalid_0's rmse: 0.429899\n",
      "[2400]\tvalid_0's rmse: 0.428773\n",
      "[2600]\tvalid_0's rmse: 0.427716\n",
      "[2800]\tvalid_0's rmse: 0.426683\n",
      "[3000]\tvalid_0's rmse: 0.425717\n",
      "[3200]\tvalid_0's rmse: 0.424844\n",
      "[3400]\tvalid_0's rmse: 0.424032\n",
      "[3600]\tvalid_0's rmse: 0.423267\n",
      "[3800]\tvalid_0's rmse: 0.422537\n",
      "[4000]\tvalid_0's rmse: 0.42173\n",
      "[4200]\tvalid_0's rmse: 0.421039\n",
      "[4400]\tvalid_0's rmse: 0.420378\n",
      "[4600]\tvalid_0's rmse: 0.419727\n",
      "[4800]\tvalid_0's rmse: 0.41911\n",
      "[5000]\tvalid_0's rmse: 0.418448\n",
      "[5200]\tvalid_0's rmse: 0.417822\n",
      "[5400]\tvalid_0's rmse: 0.417195\n",
      "[5600]\tvalid_0's rmse: 0.416579\n",
      "[5800]\tvalid_0's rmse: 0.416049\n",
      "[6000]\tvalid_0's rmse: 0.415552\n",
      "[6200]\tvalid_0's rmse: 0.414976\n",
      "[6400]\tvalid_0's rmse: 0.414436\n",
      "[6600]\tvalid_0's rmse: 0.413847\n",
      "[6800]\tvalid_0's rmse: 0.413327\n",
      "[7000]\tvalid_0's rmse: 0.412834\n",
      "[7200]\tvalid_0's rmse: 0.412372\n",
      "[7400]\tvalid_0's rmse: 0.411919\n",
      "[7600]\tvalid_0's rmse: 0.411421\n",
      "[7800]\tvalid_0's rmse: 0.410962\n",
      "[8000]\tvalid_0's rmse: 0.410519\n",
      "[8200]\tvalid_0's rmse: 0.410087\n",
      "[8400]\tvalid_0's rmse: 0.409678\n",
      "[8600]\tvalid_0's rmse: 0.409243\n",
      "[8800]\tvalid_0's rmse: 0.408821\n",
      "[9000]\tvalid_0's rmse: 0.408379\n",
      "[9200]\tvalid_0's rmse: 0.408016\n",
      "[9400]\tvalid_0's rmse: 0.407599\n",
      "[9600]\tvalid_0's rmse: 0.407226\n",
      "[9800]\tvalid_0's rmse: 0.406849\n",
      "[10000]\tvalid_0's rmse: 0.40646\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's rmse: 0.40646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  43%|####2     | 3/7 [05:33<05:32, 83.11s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  57%|#####7    | 4/7 [05:33<04:09, 83.14s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-07-09 11:31:08,226]\u001b[0m Trial 3 finished with value: 0.4064604902762252 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.40630605280755844.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  57%|#####7    | 4/7 [05:33<04:09, 83.14s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5358\n",
      "[LightGBM] [Info] Number of data points in the train set: 434105, number of used features: 22\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Info] Start training from score 0.027948\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.4521\n",
      "[400]\tvalid_0's rmse: 0.447045\n",
      "[600]\tvalid_0's rmse: 0.443651\n",
      "[800]\tvalid_0's rmse: 0.441093\n",
      "[1000]\tvalid_0's rmse: 0.439045\n",
      "[1200]\tvalid_0's rmse: 0.437327\n",
      "[1400]\tvalid_0's rmse: 0.435731\n",
      "[1600]\tvalid_0's rmse: 0.434262\n",
      "[1800]\tvalid_0's rmse: 0.432807\n",
      "[2000]\tvalid_0's rmse: 0.431555\n",
      "[2200]\tvalid_0's rmse: 0.430307\n",
      "[2400]\tvalid_0's rmse: 0.429199\n",
      "[2600]\tvalid_0's rmse: 0.428178\n",
      "[2800]\tvalid_0's rmse: 0.42711\n",
      "[3000]\tvalid_0's rmse: 0.426138\n",
      "[3200]\tvalid_0's rmse: 0.425191\n",
      "[3400]\tvalid_0's rmse: 0.424386\n",
      "[3600]\tvalid_0's rmse: 0.423604\n",
      "[3800]\tvalid_0's rmse: 0.422892\n",
      "[4000]\tvalid_0's rmse: 0.422148\n",
      "[4200]\tvalid_0's rmse: 0.421462\n",
      "[4400]\tvalid_0's rmse: 0.420771\n",
      "[4600]\tvalid_0's rmse: 0.420105\n",
      "[4800]\tvalid_0's rmse: 0.419409\n",
      "[5000]\tvalid_0's rmse: 0.418705\n",
      "[5200]\tvalid_0's rmse: 0.418083\n",
      "[5400]\tvalid_0's rmse: 0.417526\n",
      "[5600]\tvalid_0's rmse: 0.416931\n",
      "[5800]\tvalid_0's rmse: 0.416313\n",
      "[6000]\tvalid_0's rmse: 0.415743\n",
      "[6200]\tvalid_0's rmse: 0.41513\n",
      "[6400]\tvalid_0's rmse: 0.414623\n",
      "[6600]\tvalid_0's rmse: 0.414115\n",
      "[6800]\tvalid_0's rmse: 0.413648\n",
      "[7000]\tvalid_0's rmse: 0.413146\n",
      "[7200]\tvalid_0's rmse: 0.412686\n",
      "[7400]\tvalid_0's rmse: 0.412223\n",
      "[7600]\tvalid_0's rmse: 0.411757\n",
      "[7800]\tvalid_0's rmse: 0.411357\n",
      "[8000]\tvalid_0's rmse: 0.41089\n",
      "[8200]\tvalid_0's rmse: 0.410439\n",
      "[8400]\tvalid_0's rmse: 0.409992\n",
      "[8600]\tvalid_0's rmse: 0.409566\n",
      "[8800]\tvalid_0's rmse: 0.409154\n",
      "[9000]\tvalid_0's rmse: 0.408749\n",
      "[9200]\tvalid_0's rmse: 0.408334\n",
      "[9400]\tvalid_0's rmse: 0.407957\n",
      "[9600]\tvalid_0's rmse: 0.407572\n",
      "[9800]\tvalid_0's rmse: 0.407202\n",
      "[10000]\tvalid_0's rmse: 0.406823\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's rmse: 0.406823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  57%|#####7    | 4/7 [07:00<04:09, 83.14s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  71%|#######1  | 5/7 [07:00<02:48, 84.49s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-07-09 11:32:35,118]\u001b[0m Trial 4 finished with value: 0.40682341653757553 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.40630605280755844.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  71%|#######1  | 5/7 [07:00<02:48, 84.49s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5358\n",
      "[LightGBM] [Info] Number of data points in the train set: 434105, number of used features: 22\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Info] Start training from score 0.027948\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.452198\n",
      "[400]\tvalid_0's rmse: 0.447207\n",
      "[600]\tvalid_0's rmse: 0.443925\n",
      "[800]\tvalid_0's rmse: 0.441374\n",
      "[1000]\tvalid_0's rmse: 0.439175\n",
      "[1200]\tvalid_0's rmse: 0.43739\n",
      "[1400]\tvalid_0's rmse: 0.435784\n",
      "[1600]\tvalid_0's rmse: 0.434408\n",
      "[1800]\tvalid_0's rmse: 0.43301\n",
      "[2000]\tvalid_0's rmse: 0.431728\n",
      "[2200]\tvalid_0's rmse: 0.430598\n",
      "[2400]\tvalid_0's rmse: 0.429545\n",
      "[2600]\tvalid_0's rmse: 0.428496\n",
      "[2800]\tvalid_0's rmse: 0.427532\n",
      "[3000]\tvalid_0's rmse: 0.426588\n",
      "[3200]\tvalid_0's rmse: 0.425743\n",
      "[3400]\tvalid_0's rmse: 0.424849\n",
      "[3600]\tvalid_0's rmse: 0.424034\n",
      "[3800]\tvalid_0's rmse: 0.423224\n",
      "[4000]\tvalid_0's rmse: 0.422527\n",
      "[4200]\tvalid_0's rmse: 0.421757\n",
      "[4400]\tvalid_0's rmse: 0.421052\n",
      "[4600]\tvalid_0's rmse: 0.42044\n",
      "[4800]\tvalid_0's rmse: 0.419834\n",
      "[5000]\tvalid_0's rmse: 0.419207\n",
      "[5200]\tvalid_0's rmse: 0.418639\n",
      "[5400]\tvalid_0's rmse: 0.418057\n",
      "[5600]\tvalid_0's rmse: 0.417477\n",
      "[5800]\tvalid_0's rmse: 0.416894\n",
      "[6000]\tvalid_0's rmse: 0.416334\n",
      "[6200]\tvalid_0's rmse: 0.415811\n",
      "[6400]\tvalid_0's rmse: 0.415251\n",
      "[6600]\tvalid_0's rmse: 0.414726\n",
      "[6800]\tvalid_0's rmse: 0.414245\n",
      "[7000]\tvalid_0's rmse: 0.413746\n",
      "[7200]\tvalid_0's rmse: 0.413276\n",
      "[7400]\tvalid_0's rmse: 0.412779\n",
      "[7600]\tvalid_0's rmse: 0.412303\n",
      "[7800]\tvalid_0's rmse: 0.411835\n",
      "[8000]\tvalid_0's rmse: 0.411369\n",
      "[8200]\tvalid_0's rmse: 0.410922\n",
      "[8400]\tvalid_0's rmse: 0.410505\n",
      "[8600]\tvalid_0's rmse: 0.410102\n",
      "[8800]\tvalid_0's rmse: 0.40973\n",
      "[9000]\tvalid_0's rmse: 0.409342\n",
      "[9200]\tvalid_0's rmse: 0.408934\n",
      "[9400]\tvalid_0's rmse: 0.408526\n",
      "[9600]\tvalid_0's rmse: 0.408159\n",
      "[9800]\tvalid_0's rmse: 0.407781\n",
      "[10000]\tvalid_0's rmse: 0.407424\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's rmse: 0.407424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  71%|#######1  | 5/7 [08:39<02:48, 84.49s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  86%|########5 | 6/7 [08:39<01:29, 89.63s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-07-09 11:34:14,714]\u001b[0m Trial 5 finished with value: 0.40742368510345667 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.40630605280755844.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  86%|########5 | 6/7 [08:39<01:29, 89.63s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5358\n",
      "[LightGBM] [Info] Number of data points in the train set: 434105, number of used features: 22\n",
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n",
      "[LightGBM] [Info] Start training from score 0.027948\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.45186\n",
      "[400]\tvalid_0's rmse: 0.446662\n",
      "[600]\tvalid_0's rmse: 0.443165\n",
      "[800]\tvalid_0's rmse: 0.440411\n",
      "[1000]\tvalid_0's rmse: 0.438241\n",
      "[1200]\tvalid_0's rmse: 0.436429\n",
      "[1400]\tvalid_0's rmse: 0.434784\n",
      "[1600]\tvalid_0's rmse: 0.433297\n",
      "[1800]\tvalid_0's rmse: 0.431957\n",
      "[2000]\tvalid_0's rmse: 0.430693\n",
      "[2200]\tvalid_0's rmse: 0.429499\n",
      "[2400]\tvalid_0's rmse: 0.428305\n",
      "[2600]\tvalid_0's rmse: 0.427275\n",
      "[2800]\tvalid_0's rmse: 0.426302\n",
      "[3000]\tvalid_0's rmse: 0.425385\n",
      "[3200]\tvalid_0's rmse: 0.424529\n",
      "[3400]\tvalid_0's rmse: 0.423729\n",
      "[3600]\tvalid_0's rmse: 0.422981\n",
      "[3800]\tvalid_0's rmse: 0.422283\n",
      "[4000]\tvalid_0's rmse: 0.421578\n",
      "[4200]\tvalid_0's rmse: 0.42085\n",
      "[4400]\tvalid_0's rmse: 0.420141\n",
      "[4600]\tvalid_0's rmse: 0.419509\n",
      "[4800]\tvalid_0's rmse: 0.418874\n",
      "[5000]\tvalid_0's rmse: 0.418205\n",
      "[5200]\tvalid_0's rmse: 0.417631\n",
      "[5400]\tvalid_0's rmse: 0.416953\n",
      "[5600]\tvalid_0's rmse: 0.416355\n",
      "[5800]\tvalid_0's rmse: 0.415817\n",
      "[6000]\tvalid_0's rmse: 0.415287\n",
      "[6200]\tvalid_0's rmse: 0.41477\n",
      "[6400]\tvalid_0's rmse: 0.414265\n",
      "[6600]\tvalid_0's rmse: 0.413796\n",
      "[6800]\tvalid_0's rmse: 0.413284\n",
      "[7000]\tvalid_0's rmse: 0.412773\n",
      "[7200]\tvalid_0's rmse: 0.412364\n",
      "[7400]\tvalid_0's rmse: 0.411926\n",
      "[7600]\tvalid_0's rmse: 0.411447\n",
      "[7800]\tvalid_0's rmse: 0.410984\n",
      "[8000]\tvalid_0's rmse: 0.410589\n",
      "[8200]\tvalid_0's rmse: 0.41015\n",
      "[8400]\tvalid_0's rmse: 0.409723\n",
      "[8600]\tvalid_0's rmse: 0.409351\n",
      "[8800]\tvalid_0's rmse: 0.408941\n",
      "[9000]\tvalid_0's rmse: 0.408511\n",
      "[9200]\tvalid_0's rmse: 0.408119\n",
      "[9400]\tvalid_0's rmse: 0.407637\n",
      "[9600]\tvalid_0's rmse: 0.407219\n",
      "[9800]\tvalid_0's rmse: 0.406768\n",
      "[10000]\tvalid_0's rmse: 0.406361\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\tvalid_0's rmse: 0.406361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306:  86%|########5 | 6/7 [10:09<01:29, 89.63s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.406306: 100%|##########| 7/7 [10:09<00:00, 89.79s/it]\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-07-09 11:35:44,853]\u001b[0m Trial 6 finished with value: 0.40636081718089667 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.40630605280755844.\u001b[0m\n",
      "feature_fraction, val_score: 0.406306: 100%|##########| 7/7 [10:09<00:00, 87.12s/it]\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.406306:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[33m[W 2021-07-09 11:35:45,016]\u001b[0m Trial 7 failed because of the following error: LightGBMError('Check failed: (num_leaves) <= (131072) at /tmp/pip-req-build-5153luwz/compile/src/io/config_auto.cpp, line 325 .\\n')\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py37/lib/python3.7/site-packages/optuna/_optimize.py\", line 216, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/opt/anaconda3/envs/py37/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\", line 249, in __call__\n",
      "    booster = lgb.train(self.lgbm_params, train_set, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py\", line 228, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/basic.py\", line 2229, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/opt/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/basic.py\", line 1472, in construct\n",
      "    categorical_feature=self.categorical_feature, params=self.params)\n",
      "  File \"/opt/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/basic.py\", line 1270, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"/opt/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/basic.py\", line 1320, in __init_from_np2d\n",
      "    ctypes.byref(self.handle)))\n",
      "  File \"/opt/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/basic.py\", line 110, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: (num_leaves) <= (131072) at /tmp/pip-req-build-5153luwz/compile/src/io/config_auto.cpp, line 325 .\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: gamma\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=15, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=15\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "Check failed: (num_leaves) <= (131072) at /tmp/pip-req-build-5153luwz/compile/src/io/config_auto.cpp, line 325 .\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7229a0169a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                     \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                     \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                     )\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/__init__.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mauto_booster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLightGBMTuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mauto_booster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauto_booster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_feature_fraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_num_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_bagging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtune_feature_fraction_stage2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36mtune_num_leaves\u001b[0;34m(self, n_trials)\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optuna_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0;34m\"num_leaves\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m         )\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36m_tune_params\u001b[0;34m(self, target_param_names, n_trials, sampler, step_name)\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m                 \u001b[0mcatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optuna_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m             )\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         )\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             )\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/optuna/integration/_lightgbm_tuner/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid_sets\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_valid_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"valid_sets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlgbm_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mval_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_booster_best_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2227\u001b[0m                 )\n\u001b[1;32m   2228\u001b[0m             \u001b[0;31m# construct booster object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2229\u001b[0;31m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2230\u001b[0m             \u001b[0;31m# copy the parameters from train_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1470\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m   1473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m   1268\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_list_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init_from_np2d\u001b[0;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mref_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             ctypes.byref(self.handle)))\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLightGBMError\u001b[0m: Check failed: (num_leaves) <= (131072) at /tmp/pip-req-build-5153luwz/compile/src/io/config_auto.cpp, line 325 .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "!pip install optuna\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# N-Lags model check\n",
    "# !pip install yfinance\n",
    "import yfinance as yf\n",
    "# ------------------------\n",
    "import imp\n",
    "import joblib\n",
    "\n",
    "def data_process(data):\n",
    "    count = 0\n",
    "    preprocess_data = pd.DataFrame()\n",
    "\n",
    "    # # \n",
    "    os.chdir('/Users/suzukiryotaro/Desktop/python_stock/machine_learning/data_process')\n",
    "    # \n",
    "    import data_process\n",
    "    imp.reload(data_process)\n",
    "    for  file in data['symbol'] :\n",
    "        count = count +1\n",
    "        print(count)\n",
    "        print(file)\n",
    "        try:\n",
    "            df = yf.download(file, start='2014-01-01')\n",
    "            df = data_process.create_data(df)\n",
    "            df = df['2016-01-06':'2020-12-31']\n",
    "            preprocess_data = preprocess_data.append(df)\n",
    "\n",
    "        except: \n",
    "            print('errror')\n",
    "            continue\n",
    "    # drop row contains NaN\n",
    "    save_path = '/Users/suzukiryotaro/Desktop/python_stock/machine_learning/ansamble/lightgbm/optuna/preprocss_data.csv'\n",
    "    preprocess_data.dropna(inplace=True)\n",
    "    preprocess_data.to_csv(save_path)\n",
    "    print('saved')\n",
    "\n",
    "    return preprocess_data\n",
    "\n",
    "\n",
    "#\n",
    "model_stock = 'sandp500'\n",
    "path = '/Users/suzukiryotaro/Desktop/python_stock/stock_data/stock_code/sandp500.csv'\n",
    "data = pd.read_csv(path)\n",
    "print(data)\n",
    "\n",
    "#\n",
    "\n",
    "# df = data_process(data)\n",
    "\n",
    "\n",
    "\n",
    "model_name = 'lightgbm_0708_optuna'\n",
    "\n",
    "\n",
    "df = pd.read_csv(save_path, index_col=0)\n",
    "print(df)\n",
    "#\n",
    "cols =['return','sma210'\n",
    "\n",
    "          ,'ratio_sma75_30', 'ratio_sma75_150', 'ratio_sma105_30', \n",
    "          'ratio_sma105_150', 'ratio_sma135_150'\n",
    "          ,'Highest161','adosc', 'sma10', \n",
    "        'adosc-SG' ,'typical-price',\"ema270\"\n",
    "      ,'Highest121','Highest45,81days_ago',\n",
    "\n",
    "'today_by_sma30ratio','today_by_sma45ratio','today_by_sma60ratio','today_by_sma120ratio'\n",
    ",'Adjclose_today_20daysago_ratio','Adjclose_today_15daysago_ratio','Adjclose_today_10daysago_ratio','Adjclose_today_5daysago_ratio',\n",
    "\n",
    "\n",
    "          ]\n",
    "\n",
    "\n",
    "X = df[cols].copy()\n",
    "import re\n",
    "X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "y = X.pop('return')\n",
    "print(X)\n",
    "print(y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=11)\n",
    "# trainvalid\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val) \n",
    "\n",
    "params = {'metric': 'rmse',\n",
    "          'max_depth' : 20,\n",
    "          'num_leaves': 23, # 31'num_leaves': 23, # 31\n",
    "          'boosting_type': 'gbdt', # \n",
    "          'objective': 'regression', #  :   \n",
    "#           'num_leaves': 23, # 31\n",
    "          'min_data_in_leaf': 15, # 20 \n",
    "          \"learning_rate\": 0.025400643228660445,\n",
    "          'gamma':0.20387750446308275, \n",
    "          }\n",
    "\n",
    "# model = lgb.train(params,\n",
    "#                 lgb_train,\n",
    "#                 valid_sets=lgb_eval,\n",
    "#                 num_boost_round=10000,\n",
    "#                 early_stopping_rounds=100,\n",
    "#                 verbose_eval=50\n",
    "#                 )\n",
    "\n",
    "best_params, tuning_history = dict(), list()\n",
    "booster = lgb.train(params, \n",
    "                    lgb_train,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    num_boost_round=10000,\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval=200,\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "joblib.dump(model, '/Users/suzukiryotaro/Desktop/python_stock/machine_learning/ansamble/lightgbm/optuna/optuna_lightgbm.ipynb/{}.joblib'.format(model_name)) \n",
    "\n",
    "best_params = model.params\n",
    "best_params\n",
    "\n",
    "#  ()\n",
    "# .drop('return',axis=1)\n",
    "cols = list(X.columns)         # (CRIM)\n",
    "f_importance = np.array(model.feature_importance()) # \n",
    "f_importance = f_importance / np.sum(f_importance)  # ()\n",
    "df_importance = pd.DataFrame({'feature':cols, 'importance':f_importance})\n",
    "df_importance = df_importance.sort_values('importance', ascending=False) # \n",
    "display(df_importance)\n",
    "\n",
    "\n",
    "\n",
    "#  \n",
    "def plot_feature_importance(df): \n",
    "    n_features = len(df)                              # () \n",
    "    df_plot = df.sort_values('importance')            # df_importance \n",
    "    f_importance_plot = df_plot['importance'].values  #  \n",
    "    plt.barh(range(n_features), f_importance_plot, align='center') \n",
    "    cols_plot = df_plot['feature'].values             #  \n",
    "    plt.yticks(np.arange(n_features), cols_plot)      # x,y\n",
    "    plt.xlabel('Feature importance')                  # x\n",
    "    plt.ylabel('Feature')                             # y\n",
    "# \n",
    "plot_feature_importance(df_importance)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = joblib.load(\"/content/drive/MyDrive/machine_learning/light_gbm/model/{}.joblib\".format(model_name))\n",
    "\n",
    "\n",
    "# # # \n",
    "# os.chdir('/content/drive/MyDrive/machine_learning/light_gbm/backtest/')\n",
    "# # \n",
    "# import backtest_lightgbm\n",
    "# imp.reload(backtest_lightgbm)\n",
    "\n",
    "\n",
    "# model_name_list = [model_name]\n",
    "# model_list = [model]\n",
    "# backtest_lightgbm.backtest(model_list, model_name_list,model,cols)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
