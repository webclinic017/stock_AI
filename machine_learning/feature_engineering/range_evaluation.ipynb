{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fba1c13-bfa0-4c40-b79d-b84006429aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "CSCO.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../stock_data/time_series_data/nasdaq100/nasdaq100/CSCO.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ef973b33b711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0mmyclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nasdaq100'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m \u001b[0mmyclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-ef973b33b711>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#             try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_stock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m#範囲を多めに取って計算量を減らす\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             )\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../stock_data/time_series_data/nasdaq100/nasdaq100/CSCO.csv'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "import requests\n",
    "import seaborn as sns\n",
    "\n",
    "class myclass():\n",
    "    def __init__(self, model_stock):\n",
    "        self.model_stock = model_stock\n",
    "        \n",
    "        \n",
    "    def main(self):\n",
    "        #全時系列データの呼び出し\n",
    "        path = '../../stock_data/time_series_data/{}'.format(self.model_stock)\n",
    "        stock_datas = os.listdir(path)\n",
    "        count = 0\n",
    "        data = pd.DataFrame()\n",
    "        cols = ['return','sma30','sma90','sma150','sma210','sma270'\n",
    "\n",
    "                        ,'ratio_sma75_30', 'ratio_sma75_150', 'ratio_sma105_30', \n",
    "                        'ratio_sma105_150', 'ratio_sma135_30', 'ratio_sma135_150'\n",
    "\n",
    "                       ,'Highest81','Highest81,30days_ago','Highest121','Highest121,30days_ago'\n",
    "                        ,'Highest121,60days_ago','Standard_deviation_normalization30',\n",
    "                       'Standard_deviation_normalization40'\n",
    "                       ,'adosc','price-change', 'price-change-percentage', 'volume', 'amount', 'sma10', 'sma10-FP',\n",
    "        'macd', 'macd-SG', 'macd-histogram', 'cci-SG', 'mtm10', 'roc-SG', 'roc-FP', 'rsi', 'rsi-FP',\n",
    "            'adosc', 'adosc-SG', 'ar26', 'br26', 'bias20',]\n",
    "#                 print(df)\n",
    "        for i in stock_datas:\n",
    "            \n",
    "            count = count +1\n",
    "            print(count)\n",
    "            print(i)\n",
    "#             try:\n",
    "            df = pd.read_csv('{}/{}/'.format(path,self.model_stock) + i)\n",
    "            df = df.set_index('Date')\n",
    "            #範囲を多めに取って計算量を減らす\n",
    "            df = df['2017-01-01':'2021-3-31']\n",
    "\n",
    "            df = create_data(df)\n",
    "\n",
    "\n",
    "            print(df.isnull().any())\n",
    "            data = data.append(df)\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "#             except:\n",
    "#                 continue\n",
    "#             # save_path = '/content/drive/MyDrive/LSTM/model1/model/preprocess_data/{}/'.format(self.model_stock)\n",
    "#             save_path = '/content/drive/MyDrive/LSTM/model1/backtest/preprocess_data/{}/'.format(self.model_stock)\n",
    "#             save_csv(df[cols], i, save_path)\n",
    "\n",
    "        \n",
    "        for i in cols:\n",
    "            \n",
    "            x = data[i]\n",
    "            sns.distplot(x)\n",
    "\n",
    "\n",
    "def create_data(df):\n",
    "    # feature calculation\n",
    "    # basic information\n",
    "    df['price-change'] = df['Adj Close'] - df['Adj Close'].shift(1)\n",
    "    df['price-change-percentage'] = df['Adj Close'] / df['Adj Close'].shift(1)\n",
    "\n",
    "    df['amount'] = df['Adj Close'] * df['Volume']\n",
    "\n",
    "    # simple moving average\n",
    "    df['sma10'] = df['Adj Close'].rolling(30).mean()\n",
    "    df['sma10-FP'] = (df['sma10'] - df['sma10'].shift(1)) / df['sma10'].shift(1)\n",
    " \n",
    "    # Moving Average Convergence Divergence\n",
    "    df['macd'] = df['Adj Close'].rolling(12).mean() - df['Adj Close'].rolling(26).mean()\n",
    "    df['macd-SG'] = df['macd'].rolling(9).mean()\n",
    "    df['macd-histogram'] = df['macd'] - df['macd-SG']\n",
    "    df['macd-histogram'] = np.where(df['macd-histogram'] > 0, 1, -1)\n",
    "    df['macd-SG'] = np.where(df['macd-SG'] > 0, 1, -1)\n",
    "    df['macd'] = np.where(df['macd'] > 0, 1, -1)\n",
    "    # Commodity Channel Index in 24 days\n",
    "    df['typical-price'] = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "    df['sma-cci'] = df['typical-price'].rolling(24).mean()\n",
    "    df['mean-deviation'] = np.abs(df['typical-price'] - df['sma-cci'])\n",
    "    df['mean-deviation'] = df['mean-deviation'].rolling(24).mean()\n",
    "    df['cci'] = (df['typical-price'] - df['sma-cci']) / (0.015 * df['mean-deviation'])\n",
    "    df['cci-SG'] = np.where(df['cci'] > 0, 1, -1)\n",
    "    # MTM 10\n",
    "    df['mtm10'] = df['Adj Close'] - df['Adj Close'].shift(10)\n",
    "    df['mtm10'] = np.where(df['mtm10'] > 0, 1, -1)\n",
    "    # Rate of Change in 10 days\n",
    "    df['roc'] = (df['Adj Close'] - df['Adj Close'].shift(10)) / df['Adj Close'].shift(10)\n",
    "    df['roc-SG'] = np.where(df['roc'] > 0, 1, -1)\n",
    "    df['roc-FP'] = (df['roc'] - df['roc'].shift(1))\n",
    "\n",
    "    # Relative Strength Index in 5 days\n",
    "    df['rsi'] = df['price-change'].rolling(5).apply(RSI) / 100\n",
    "    df['rsi-FP'] = (df['rsi'] - df['rsi'].shift(1))\n",
    "\n",
    "    # Slow K and Slow D\n",
    "#     df['slow-k'] = df['Adj Close'].rolling(14).apply(SlowK)\n",
    "#     df['slow-d'] = df['slow-k'].rolling(14).mean()\n",
    "#     df['slow-k-FP'] = df['slow-k'] - df['slow-k'].shift(1)\n",
    "#     df['slow-d-FP'] = df['slow-d'] - df['slow-d'].shift(1)\n",
    "#     df['slow-k'] = Zero_One_Scale(df['slow-k'])\n",
    "#     df['slow-d'] = Zero_One_Scale(df['slow-d'])\n",
    "#     df['slow-k-FP'] = One_One_Scale(df['slow-k-FP'])\n",
    "#     df['slow-d-FP'] = One_One_Scale(df['slow-d-FP'])\n",
    "    # ADOSC\n",
    "    df['adosc'] = ((2 * df['Close'] - df['High'] - df['Low']) / (df['High'] - df['Low'])) * df['Volume']\n",
    "    df['adosc'] = df['adosc'].cumsum()\n",
    "    df['adosc-ema3'] = df['adosc'].ewm(span=3, adjust=False).mean()\n",
    "    df['adosc-ema10'] = df['adosc'].ewm(span=10, adjust=False).mean()\n",
    "    df['adosc-SG'] = np.where((df['adosc-ema3'] - df['adosc-ema10']) > 0, 1, -1)\n",
    "\n",
    "    # AR 26\n",
    "    hp_op = (df['High'] - df['Open']).rolling(26).sum()\n",
    "    op_lp = (df['Open'] - df['Low']).rolling(26).sum()\n",
    "    df['ar26'] = hp_op / op_lp\n",
    "\n",
    "    # BR 26\n",
    "    hp_cp = (df['High'] - df['Close']).rolling(26).sum()\n",
    "    cp_lp = (df['Close'] - df['Low']).rolling(26).sum()\n",
    "    df['br26'] = hp_cp / cp_lp\n",
    "\n",
    "    # VR 26\n",
    "    \n",
    "    # BIAS 20\n",
    "    sma20 = df['Adj Close'].rolling(20).mean()\n",
    "    df['bias20'] = (df['Adj Close'] - sma20) / sma20\n",
    "    df['bias20'] = np.where(df['bias20'] > 0, 1, -1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df['price-change'] = One_One_Scale(df['price-change'])\n",
    "    # set return and direction (label)\n",
    "    df['return'] = np.log(df['Adj Close'].shift(-5) / df['Adj Close'])\n",
    "    df['direction'] = np.where(df['return'] > 0, 1, -1)\n",
    "    df['direction'] = df['direction'].shift(-1)\n",
    "    \n",
    "    AD = []\n",
    "    AD.append(0)\n",
    "    for i in range(1, len(df)):\n",
    "        AD_component = ((df[\"Adj Close\"][i] - df[\"Low\"][i]) - (df[\"High\"][i] - df[\"Adj Close\"][i])) * df['Volume'][i] / (df[\"High\"][i] - df[\"Low\"][i]) + AD[-1]\n",
    "        AD.append(AD_component)\n",
    "    df['A/D'] = AD\n",
    "    df['A/D_EMA'] = df['A/D'].ewm(com=20).mean()   \n",
    "    df['A/D_ratio'] = df['A/D'] / df['A/D_EMA']\n",
    "    df['ADOSC'] = df['A/D'].ewm(com=3).mean() / df['A/D'].ewm(com=10).mean()   \n",
    "    df['A/D_EMA_ratio'] = df['A/D_EMA'] / df['A/D_EMA'].shift(1)\n",
    "                \n",
    "#     df['A/D'] = Zero_One_Scale(df['A/D'])\n",
    "#     df['A/D_EMA'] = Zero_One_Scale(df['A/D_EMA'])\n",
    "#     df['A/D_ratio'] = Zero_One_Scale(df['A/D_ratio'])\n",
    "#     df['A/D_EMA_ratio'] = Zero_One_Scale(df['A/D_ratio'])\n",
    "#     df['ADOSC'] = Zero_One_Scale(df['ADOSC'])\n",
    "   \n",
    "    \n",
    "    \n",
    "    OBV = []\n",
    "    OBV.append(0)\n",
    "    for i in range(1, len(df.Close)):\n",
    "        if df.Close[i] > df.Close[i-1]: #If the closing price is above the prior close price \n",
    "              OBV.append(OBV[-1] + df.Volume[i]) #then: Current OBV = Previous OBV + Current Volume\n",
    "        elif df.Close[i] < df.Close[i-1]:\n",
    "              OBV.append( OBV[-1] - df.Volume[i])\n",
    "        else:\n",
    "              OBV.append(OBV[-1])\n",
    "                \n",
    "    #Store the OBV and OBV EMA into new columns\n",
    "    df['OBV'] = OBV\n",
    "    df['OBV_EMA'] = df['OBV'].ewm(com=20).mean()   \n",
    "    df['OBV_ratio'] = df['OBV'] / df['OBV_EMA']\n",
    "    \n",
    "    df['OBV_EMA_ratio'] =  df['OBV_EMA'] / df['OBV_EMA'].shift(1)\n",
    "                \n",
    "#     df['OBV'] = Zero_One_Scale(df['OBV'])\n",
    "#     df['OBV_EMA'] = Zero_One_Scale(df['OBV_EMA'])\n",
    "#     df['OBV_ratio'] = Zero_One_Scale(df['OBV_ratio'])\n",
    "#     df['OBV_EMA_ratio'] = Zero_One_Scale(df['OBV_EMA_ratio'])\n",
    "\n",
    "     # Commodity Channel Index in 24 days\n",
    "    df['typical-price'] = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "   \n",
    "    \n",
    "\n",
    "    # simple moving average\n",
    "    for i in [30,45,60,90,120,150,180,200,210,240,270,300]:\n",
    "        df['sma'+str(i)] = df['Adj Close'].rolling(i).mean()\n",
    "        df['sma'+str(i)] = df['sma'+str(i)] / df['sma'+str(i)].shift(1)\n",
    "#         df['sma'+str(i)] = Zero_One_Scale(df['sma'+str(i)])\n",
    "    for i in [30,60,90,120,150,180,200,210,240,270,300]:\n",
    "        df[\"ema\"+str(i)]=df[\"Adj Close\"].ewm(span=i).mean()\n",
    "        df[\"ema\"+str(i)] = df[\"ema\"+str(i)] / df[\"ema\"+str(i)].shift(1)\n",
    "#         df[\"ema\"+str(i)] = Zero_One_Scale(df[\"ema\"+str(i)])\n",
    "    \n",
    "    \n",
    "    #calucurate aroon\n",
    "    for periods in [14,20]:\n",
    "        df['aroon_up'+str(periods)] = df['High'].rolling(periods+1).apply(lambda x: x.argmax(), raw=True) / periods * 100\n",
    "        df['aroon_down'+str(periods)] = df['Low'].rolling(periods+1).apply(lambda x: x.argmin(), raw=True) / periods * 100\n",
    "        df['aroon_ratio'+str(periods)] = df['aroon_up'+str(periods)] / df['aroon_down'+str(periods)]\n",
    "#         df['AROONOSC'+str(periods)] = df['aroon_up'+str(periods)] - df['aroon_down'+str(periods)]\n",
    "\n",
    "        df['aroon_up'+str(periods)] = Zero_One_Scale(df['aroon_up'+str(periods)])\n",
    "        df['aroon_down'+str(periods)] = Zero_One_Scale(df['aroon_down'+str(periods)])\n",
    "        df['aroon_ratio'+str(periods)] = Zero_One_Scale(df['aroon_up'+str(periods)])\n",
    "#         df['AROONOSC'+str(periods)] = Zero_One_Scale(df['AROONOSC'+str(periods)])\n",
    "\n",
    "\n",
    "     #calucurate ADX\n",
    "    df[\"TrueRange\"] = np.nan\n",
    "    df[\"PDM\"] = np.nan\n",
    "    df[\"NDM\"] = np.nan\n",
    "    for i in range(1,len(df)):\n",
    "        df[\"TrueRange\"][i] = TrueRange(df[\"Adj Close\"][i],df[\"High\"][i],df[\"Low\"][i],df[\"Open\"][i],df[\"Adj Close\"][i-1])\n",
    "        df[\"PDM\"][i] = PDM(df[\"Open\"][i],df[\"High\"][i],df[\"Low\"][i],df[\"Adj Close\"][i],df[\"Open\"][i-1],df[\"High\"][i-1],df[\"Low\"][i-1],df[\"Adj Close\"][i-1])\n",
    "        df[\"NDM\"][i] = NDM(df[\"Open\"][i],df[\"High\"][i],df[\"Low\"][i],df[\"Adj Close\"][i],df[\"Open\"][i-1],df[\"High\"][i-1],df[\"Low\"][i-1],df[\"Adj Close\"][i-1])\n",
    "    \n",
    "    df['PDI'] = df[\"PDM\"].rolling(14).sum()/df[\"TrueRange\"].rolling(14).sum() * 100\n",
    "    df['NDI'] = df[\"NDM\"].rolling(14).sum()/df[\"TrueRange\"].rolling(14).sum() * 100\n",
    "\n",
    "    \n",
    "    df['DX'] = (df['PDI']-df['NDI']).abs()/(df['PDI']+df['NDI']) * 100\n",
    "    df['DX'] = df['DX'].fillna(0)\n",
    "    \n",
    "    df['ADX'] = df['DX'].rolling(14).mean()\n",
    "    df['ADXR'] = df['ADX'].rolling(14).mean()\n",
    "    \n",
    "#     df['ADX'] = Zero_One_Scale(df['ADX'])\n",
    "#     df['ADXR'] = Zero_One_Scale(df['ADXR'])\n",
    "    \n",
    "    \n",
    "    for i in range(15,150,30):\n",
    "        for k in range(30,270,60):\n",
    "            df['ratio_sma'+str(k)] = df['Adj Close'].rolling(k).mean()\n",
    "            df['ratio_sma'+str(i)] = df['Adj Close'].rolling(i).mean()\n",
    "            df['ratio_sma'+str(i)+'_'+str(k)] = df['ratio_sma'+str(i)] / df['ratio_sma'+str(k)]\n",
    "#             df['ratio_sma'+str(i)+'_'+str(k)] = Zero_One_Scale(df['ratio_sma'+str(i)])\n",
    "\n",
    "            \n",
    "    for term in range(5,50,5):\n",
    "        df['SMA'+str(term)] = df['Adj Close'].rolling(term).mean()\n",
    "        df['STD'+str(term)] = df['Adj Close'].rolling(term).std()\n",
    "        df['Standard_deviation_normalization'+str(term)] = 100 * 2 * df['STD'+str(term)] / df['SMA'+str(term)]\n",
    "#         df['Standard_deviation_normalization'+str(term)] = Zero_One_Scale(df['Standard_deviation_normalization'+str(term)])\n",
    "        \n",
    "    for i in [15,45,81,121,161]:\n",
    "        df['Highest'+str(i)] = df['Adj Close'].rolling(window=81).max()\n",
    "        df['Highest'+str(i)] = df['Highest'+str(i)].shift()\n",
    "        for m in [30,90,150,60,60]:\n",
    "            df['Highest'+str(i)+','+str(m)+'days_ago'] = df['Adj Close'] / df['Highest'+str(i)].shift(m)\n",
    "#             df['Highest'+str(i)+','+str(m)+'days_ago'] = Zero_One_Scale(df['Highest'+str(i)+','+str(m)+'days_ago'])\n",
    "        \n",
    "        #今日の終値が過去何日間の高音に対してどの程度あるか\n",
    "        df['Highest'+str(i)] = df['Adj Close'] / df['Highest'+str(i)]\n",
    "#         df['Highest'+str(i)] = Zero_One_Scale(df['Highest'+str(i)])\n",
    "        \n",
    "    # ADOSC\n",
    "    df['adosc'] = ((2 * df['Close'] - df['High'] - df['Low']) / (df['High'] - df['Low'])) * df['Volume']\n",
    "    df['adosc'] = df['adosc'].cumsum()\n",
    "#     df['adosc'] = Zero_One_Scale(df['adosc'])\n",
    "        \n",
    "\n",
    "\n",
    "    validation(df)\n",
    "    # drop row contains NaN\n",
    "    df.dropna(inplace=True)\n",
    "    # adjust the length of the data, which should be a multiple number of 30.\n",
    "    length = len(df) // 5\n",
    "    \n",
    "    return df[:5 * length]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def validation(df):\n",
    "    k=5\n",
    "    df[\"Open\"] = df[\"Open\"].shift(-1)\n",
    "    df[\"validation\"] = np.nan\n",
    "    for i in range(0,len(df)-k):\n",
    "\n",
    "        df[\"validation\"][i] = df['Adj Close'][i+k]/df['Open'][i]\n",
    "\n",
    "#     df[\"validation\"] = Zero_One_Scale(df[\"validation\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "def TrueRange(c, h, l, o, yc):\n",
    "    x = h-l\n",
    "    y = abs(h-yc)\n",
    "    z = abs(l-yc)\n",
    "    if y <= x >= z:\n",
    "        TR = x\n",
    "    elif x <= y >= z:\n",
    "        TR = y\n",
    "    elif x <= z >= y:\n",
    "        TR = z\n",
    "    return TR\n",
    "\n",
    "def PDM(o, h, l, c, yo, yh, yl, yc):\n",
    "    moveUp = h - yh\n",
    "    moveDown = yl - l\n",
    "    if 0 < moveUp > moveDown:\n",
    "        PDM = moveUp\n",
    "    else:\n",
    "        PDM = 0\n",
    "        \n",
    "    return PDM\n",
    "\n",
    "def NDM(o, h, l, c, yo, yh, yl, yc):\n",
    "    moveDown = yl - l\n",
    "    moveUp = h - yh\n",
    "    if 0 < moveDown > moveUp:\n",
    "        NDM = moveDown\n",
    "    else:\n",
    "        NDM = 0\n",
    "    \n",
    "    return NDM\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def save_csv(df, sym, save_path):\n",
    "    sym = sym.replace('.T', '')\n",
    "    df.to_csv(save_path+'{}'.format(sym))\n",
    "    print('{}.csv Saved'.format(sym))\n",
    "\n",
    "    \n",
    "    \n",
    "myclass = myclass('nasdaq100')\n",
    "myclass.main()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
